{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find candidates with DeezyMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "from DeezyMatch import combine_vecs\n",
    "from DeezyMatch import candidate_ranker\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findcandidates(candidates, queries, dm_model, inputfile, overwrite=False):\n",
    "    \n",
    "    # --------------------------------------\n",
    "    # GENERATE AND COMBINE CANDIDATE VECTORS\n",
    "    \n",
    "    # generate vectors for candidates (specified in dataset_path) \n",
    "    # using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "    if not Path(\"./candidates/\" + candidates + \"_\" + dm_model + \"/embeddings/\").is_dir() or overwrite == True:\n",
    "        start_time = time.time()\n",
    "        dm_inference(input_file_path=\"./models/\" + dm_model + \"/\" + inputfile + \".yaml\",\n",
    "                     dataset_path=\"./gazetteers/\" + candidates + \".txt\", \n",
    "                     pretrained_model_path=\"./models/\" + dm_model + \"/\" + dm_model + \".model\", \n",
    "                     pretrained_vocab_path=\"./models/\" + dm_model + \"/\" + dm_model + \".vocab\",\n",
    "                     inference_mode=\"vect\",\n",
    "                     scenario=\"candidates/\" + candidates + \"_\" + dm_model)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(\"Generate candidate vectors: %s\" % elapsed)\n",
    "\n",
    "    # combine vectors stored in the scenario in candidates/ and save them in combined/\n",
    "    if not Path(\"./combined/\" + candidates + \"_\" + dm_model).is_dir() or overwrite == True:\n",
    "        start_time = time.time()\n",
    "        combine_vecs(rnn_passes=[\"fwd\", \"bwd\"], \n",
    "                     input_scenario=\"candidates/\" + candidates + \"_\" + dm_model, \n",
    "                     output_scenario=\"combined/\" + candidates + \"_\" + dm_model, \n",
    "                     print_every=100)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(\"Combine candidate vectors: %s\" % elapsed)\n",
    "    \n",
    "    # --------------------------------------\n",
    "    # GENERATE AND COMBINE QUERY VECTORS\n",
    "    \n",
    "    # generate vectors for queries (specified in dataset_path) \n",
    "    # using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "    if not Path(\"./queries/\" + queries + \"_\" + dm_model + \"/embeddings/\").is_dir() or overwrite == True:\n",
    "        start_time = time.time()\n",
    "        dm_inference(input_file_path=\"./models/\" + dm_model + \"/\" + inputfile + \".yaml\",\n",
    "                     dataset_path=\"./toponyms/\" + queries + \".txt\", \n",
    "                     pretrained_model_path=\"./models/\" + dm_model + \"/\" + dm_model + \".model\", \n",
    "                     pretrained_vocab_path=\"./models/\" + dm_model + \"/\" + dm_model + \".vocab\",\n",
    "                     inference_mode=\"vect\",\n",
    "                     scenario=\"queries/\" + queries + \"_\" + dm_model)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(\"Generate candidate vectors: %s\" % elapsed)\n",
    "\n",
    "    # combine vectors stored in the scenario in queries/ and save them in combined/\n",
    "    if not Path(\"./combined/\" + queries + \"_\" + dm_model).is_dir() or overwrite == True:\n",
    "        start_time = time.time()\n",
    "        combine_vecs(rnn_passes=[\"fwd\", \"bwd\"], \n",
    "                     input_scenario=\"queries/\" + queries + \"_\" + dm_model, \n",
    "                     output_scenario=\"combined/\" + queries + \"_\" + dm_model, \n",
    "                     print_every=100)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(\"Combine candidate vectors: %s\" % elapsed)\n",
    "        \n",
    "    # Select candidates based on L2-norm distance (aka faiss distance):\n",
    "    # find candidates from candidate_scenario \n",
    "    # for queries specified in query_scenario\n",
    "    if not Path(\"ranker_results/\" + queries + \"_\" + candidates + \"_\" + dm_model + \".pkl\").is_file() or overwrite == True:\n",
    "        start_time = time.time()\n",
    "        candidates_pd = \\\n",
    "            candidate_ranker(query_scenario=\"./combined/\" + queries + \"_\" + dm_model,\n",
    "                             candidate_scenario=\"./combined/\" + candidates + \"_\" + dm_model, \n",
    "                             ranking_metric=\"faiss\", \n",
    "                             selection_threshold=100., \n",
    "                             num_candidates=20, \n",
    "                             search_size=20, \n",
    "                             output_path=\"ranker_results/\" + queries + \"_\" + candidates + \"_\" + dm_model, \n",
    "                             pretrained_model_path=\"./models/\" + dm_model + \"/\" + dm_model + \".model\", \n",
    "                             pretrained_vocab_path=\"./models/\" + dm_model + \"/\" + dm_model + \".vocab\")\n",
    "        elapsed = time.time() - start_time\n",
    "        print(\"Rank candidates: %s\" % elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = \"britwikidata_candidates\"\n",
    "queries = \"bho_queries\"\n",
    "dm_model = \"wikigaz_en_001\"\n",
    "inputfile = \"input_dfm_001\"\n",
    "overwrite = True\n",
    "\n",
    "findcandidates(candidates, queries, dm_model, inputfile, overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"ranker_results/\" + queries + \"_\" + candidates + \"_\" + dm_model + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[350:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37deezy)",
   "language": "python",
   "name": "py37deezy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
