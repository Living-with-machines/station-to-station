{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Wikidata candidates\n",
    "\n",
    "Two main outputs from this notebook:\n",
    "- [x] Generate a altname-centric British Wikidata gazetteer: `gazetteers/britwikidata_gazetteer.pkl`\n",
    "- [x] Generate the candidates (aka unique altnames) input file for candidate ranker: `gazetteers/britwikidata_candidates.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from collections import Counter\n",
    "from  itertools import chain\n",
    "import pydash\n",
    "import ast\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load British wikidata\n",
    "\n",
    "The `british_isles.csv` file is one output from `entity_extraction.py`. Running `entity_extraction.py` takes days, so for the time being you can find this file in the `ToponymVM` under `/home/mcollardanuy/PlaceLinking/wikidata/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "britdf = pd.read_csv(\"british_isles.csv\", header=0, index_col=None, low_memory=False)\n",
    "britdf = britdf.drop(columns=['Unnamed: 0'])\n",
    "britdf['latitude'] = britdf['latitude'].astype(float)\n",
    "britdf['longitude'] = britdf['longitude'].astype(float)\n",
    "britdf = britdf[britdf['latitude'].notna()]\n",
    "britdf = britdf[britdf['longitude'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "britdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add geonames alternate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(\"/resources/geonames/alternateNamesV2.txt\").exists():\n",
    "    !wget http://download.geonames.org/export/dump/alternateNamesV2.zip\n",
    "    !unzip alternateNamesV2.zip\n",
    "    !rm alternateNamesV2.zip\n",
    "    !rm iso-languagecodes.txt\n",
    "    !mv alternateNamesV2.txt /resources/geonames/alternateNamesV2.txt\n",
    "    \n",
    "if not Path(\"/resources/geonames/GB.txt\").exists():\n",
    "    !wget http://download.geonames.org/export/dump/GB.zip\n",
    "    !unzip GB.zip\n",
    "    !rm readme.txt\n",
    "    !rm GB.zip\n",
    "    !mv GB.txt /resources/geonames/GB.txt\n",
    "    \n",
    "if not Path(\"/resources/geonames/IE.txt\").exists():\n",
    "    !wget http://download.geonames.org/export/dump/IE.zip\n",
    "    !unzip IE.zip\n",
    "    !rm readme.txt\n",
    "    !rm IE.zip\n",
    "    !mv IE.txt /resources/geonames/IE.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process alternate names table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoaltnames = pd.read_csv(\"/resources/geonames/alternateNamesV2.txt\", sep=\"\\t\", names=[\"alternateNameId\", \"geonameid\", \"isolanguage\", \"alternateName\", \"isPreferredName\", \"isShortName\", \"isColloquial\", \"isHistoric\", \"from\", \"to\"], index_col=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out alternate names that are actually pseudocodes:\n",
    "gn_pseudocodes = [\"post\", \"link\", \"iata\", \"icao\",\n",
    "                  \"faac\", \"tcid\", \"unlc\", \"abbr\",\n",
    "                  \"wkdt\", \"phon\", \"piny\", \"fr_1793\"] # Geonames pseucodes from here: https://www.geonames.org/manual.html\n",
    "\n",
    "geoaltnames = geoaltnames[~geoaltnames[\"isolanguage\"].isin(gn_pseudocodes)]\n",
    "\n",
    "# Filter by languages native to the British Isles or with strong influence in toponymy:\n",
    "# gd: Scottish Gaelic\n",
    "# kw: Cornish\n",
    "# sco: Scots\n",
    "# cy: Welsh\n",
    "# ga: Irish\n",
    "# en: English\n",
    "# gv: Manx\n",
    "# br: Breton\n",
    "# fr: French\n",
    "# la: Latin\n",
    "gn_toplanguages = [\"gd\", \"kw\", \"sco\", \"cy\", \"ga\", \"en\", \"gv\", \"br\", \"fr\", \"la\"]\n",
    "geoaltnames = geoaltnames[(geoaltnames[\"isolanguage\"].isin(gn_toplanguages)) | (geoaltnames[\"isolanguage\"].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoaltnames = geoaltnames.drop(columns=[\"alternateNameId\", \"isolanguage\", \"isPreferredName\", \"isShortName\", \"isColloquial\", \"isHistoric\", \"from\", \"to\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoaltnames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process GB and IE geonames tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country: GB (United Kingdom)\n",
    "gb_geonames = pd.read_csv(\"/resources/geonames/GB.txt\", sep=\"\\t\", names=[\"geonameid\", \"name\", \"asciiname\", \"alternatenames\", \"latitude\", \"longitude\", \"fclass\", \"fcode\", \"ccode\", \"cc2\", \"admin1\", \"admin2\", \"admin3\", \"admin4\", \"population\", \"elevation\", \"dem\", \"timezone\", \"moddate\"], index_col=None, low_memory=False)\n",
    "gb_geonames = gb_geonames.drop(columns=[\"alternatenames\", \"latitude\", \"longitude\", \"fclass\", \"fcode\", \"ccode\", \"cc2\", \"admin1\", \"admin2\", \"admin3\", \"admin4\", \"population\", \"elevation\", \"dem\", \"timezone\", \"moddate\"])\n",
    "gb_altnames = list(set(gb_geonames.groupby(['geonameid', 'name']).groups))\n",
    "gb_altnames.extend(list(set(gb_geonames.groupby(['geonameid', 'asciiname']).groups)))\n",
    "gb_altnames = list(set(gb_altnames))\n",
    "gb_geonames = pd.DataFrame(gb_altnames, columns = [\"geonameid\", \"alternateName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country: IE (Ireland)\n",
    "ie_geonames = pd.read_csv(\"/resources/geonames/IE.txt\", sep=\"\\t\", names=[\"geonameid\", \"name\", \"asciiname\", \"alternatenames\", \"latitude\", \"longitude\", \"fclass\", \"fcode\", \"ccode\", \"cc2\", \"admin1\", \"admin2\", \"admin3\", \"admin4\", \"population\", \"elevation\", \"dem\", \"timezone\", \"moddate\"], index_col=None, low_memory=False)\n",
    "ie_geonames = ie_geonames.drop(columns=[\"alternatenames\", \"latitude\", \"longitude\", \"fclass\", \"fcode\", \"ccode\", \"cc2\", \"admin1\", \"admin2\", \"admin3\", \"admin4\", \"population\", \"elevation\", \"dem\", \"timezone\", \"moddate\"])\n",
    "ie_altnames = list(set(ie_geonames.groupby(['geonameid', 'name']).groups))\n",
    "ie_altnames.extend(list(set(ie_geonames.groupby(['geonameid', 'asciiname']).groups)))\n",
    "ie_altnames = list(set(ie_altnames))\n",
    "ie_geonames = pd.DataFrame(ie_altnames, columns = [\"geonameid\", \"alternateName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_geonames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate all altname dataframes and filter relevant rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geonames_altnames = pd.concat([geoaltnames, gb_geonames, ie_geonames], ignore_index=True)\n",
    "geonames_altnames = geonames_altnames.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out alternate names if they are not in Latin alphabet:\n",
    "def latin_alphabet(toponym):\n",
    "    latin_range = re.compile(u'[\\u0040-\\u007F\\u0080-\\u00FF\\u0100-\\u017F\\u0180-\\u024F]', flags=re.UNICODE)\n",
    "    if re.search(latin_range, toponym):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "geonames_altnames = geonames_altnames[geonames_altnames.apply(lambda x: latin_alphabet(x[\"alternateName\"]), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geonames_altnames[geonames_altnames[\"geonameid\"] == 7297387]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows that have a corresponding Wikidata entry\n",
    "def parse_geonames(geoIDs):\n",
    "    geonamesIDs = []\n",
    "    if type(geoIDs) == str:\n",
    "        geonamesIDs = ast.literal_eval(geoIDs)\n",
    "        geonamesIDs = [int(gn) for gn in geonamesIDs if type(gn) == str]\n",
    "    return geonamesIDs\n",
    "\n",
    "brit_geonameIDs = []\n",
    "for i, row in britdf.iterrows():\n",
    "    tmp_gnalt = parse_geonames(row[\"geonamesIDs\"])\n",
    "    if tmp_gnalt:\n",
    "        brit_geonameIDs.extend(tmp_gnalt)\n",
    "\n",
    "geonames_altnames = geonames_altnames[geonames_altnames[\"geonameid\"].isin(brit_geonameIDs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geonames_altnames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create altname-focused gazetteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_wikidata_altnames(elabel, aliases, nativelabel):\n",
    "    re_appo = r\"(.+)\\(.+\\)$\"\n",
    "    altnames = dict()\n",
    "    if type(elabel) == str:\n",
    "        if re.match(re_appo, elabel):\n",
    "            elabel = re.match(re_appo, elabel).group(1).strip()\n",
    "            elabel = re.sub(\",$\", \"\", elabel)\n",
    "        if not elabel in altnames:\n",
    "            altnames[elabel] = \"english_label\"\n",
    "    if type(aliases) == str:\n",
    "        aliases = ast.literal_eval(aliases)\n",
    "        for language in aliases:\n",
    "            for a in aliases[language]:\n",
    "                if not a in altnames:\n",
    "                    altnames[a] = \"wikidata_alias\"\n",
    "    if type(nativelabel) == str:\n",
    "        nlabel = ast.literal_eval(nativelabel)\n",
    "        for nl in nlabel:\n",
    "            if not nl in altnames:\n",
    "                altnames[nl] = \"native_label\"\n",
    "    return altnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_geonames_altnames(geonamesIDs, geoaltnames, altnames):\n",
    "    if type(geonamesIDs) == str:\n",
    "        geonamesIDs = ast.literal_eval(geonamesIDs)\n",
    "        for gid in geonamesIDs:\n",
    "            if type(gid) == str:\n",
    "                tmp_gndf = geoaltnames[geoaltnames[\"geonameid\"] == int(gid)]\n",
    "                if not tmp_gndf.empty:\n",
    "                    for i, row in tmp_gndf.iterrows():\n",
    "                        if not row[\"alternateName\"] in altnames:\n",
    "                            altnames[row[\"alternateName\"]] = \"geonames\"\n",
    "    return altnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_candranker(gazname, unique_placenames_array):\n",
    "    \"\"\"\n",
    "    This function returns the unique alternate names in a given gazetteer\n",
    "    in the format required by DeezyMatch candidate ranker.\"\"\"\n",
    "    with open(gazname + \".txt\", \"w\") as fw:\n",
    "        for pl in unique_placenames_array:\n",
    "            pl = pl.strip()\n",
    "            if pl:\n",
    "                pl = pl.replace('\"', \"\")\n",
    "                fw.write(pl.strip() + \"\\t0\\tfalse\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create generic British Isles gazetteer and candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkid = []\n",
    "altname = []\n",
    "source = []\n",
    "lat = []\n",
    "lon = []\n",
    "for i, row in britdf.iterrows():\n",
    "    dAltnames = obtain_wikidata_altnames(row[\"english_label\"], row[\"alias_dict\"], row[\"nativelabel\"])\n",
    "    if dAltnames: # Entities without any alternate names are likely to be ghost entities, e.g. Q24663377\n",
    "        dAltnames = obtain_geonames_altnames(row[\"geonamesIDs\"], geonames_altnames, dAltnames)\n",
    "    for a in dAltnames:\n",
    "        if a:\n",
    "            if type(a) == str:\n",
    "                wkid.append(row[\"wikidata_id\"])\n",
    "                altname.append(a)\n",
    "                source.append(dAltnames[a])\n",
    "                lat.append(row[\"latitude\"])\n",
    "                lon.append(row[\"longitude\"])\n",
    "                \n",
    "wkgazetteer = pd.DataFrame()\n",
    "wkgazetteer[\"wkid\"] = wkid\n",
    "wkgazetteer[\"altname\"] = altname\n",
    "wkgazetteer[\"source\"] = source\n",
    "wkgazetteer[\"lat\"] = lat\n",
    "wkgazetteer[\"lon\"] = lon\n",
    "\n",
    "wkgazetteer = wkgazetteer.drop_duplicates(subset = ['wkid', 'altname'])\n",
    "wkgazetteer = wkgazetteer[wkgazetteer['altname'].notna()]\n",
    "wkgazetteer.to_pickle(\"../toponym_matching/gazetteers/britwikidata_gazetteer.pkl\")\n",
    "unique_placenames_array = list(set(list(np.array(wkgazetteer[\"altname\"]))))\n",
    "format_for_candranker(\"../toponym_matching/gazetteers/britwikidata_candidates\", unique_placenames_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkgazetteer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create gazetteer and candidates of railway stations from British Isles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationgaz = wkgazetteer[wkgazetteer[\"altname\"].str.contains(r\"\\b(?:station|stop|halt|railway)\\b\", case=False, regex=True)]\n",
    "station_altnames = stationgaz.wkid.to_list()\n",
    "\n",
    "# From: https://docs.google.com/spreadsheets/d/1sREU_TKBU0HXoSSm7nyOw-4kId_bfu6OTEXxtdZeLl0/edit#gid=0\n",
    "stn_wkdt_classes = [\"Q55488\", \"Q4663385\", \"Q55491\", \"Q18516630\", \"Q1335652\", \"Q28109487\",\n",
    "                    \"Q55678\", \"Q1567913\", \"Q39917125\", \"Q11424045\", \"Q14562709\", \"Q27020748\",\n",
    "                    \"Q22808403\", \"Q85641138\", \"Q928830\", \"Q1339195\", \"Q27030992\", \"Q55485\",\n",
    "                    \"Q17158079\", \"Q55493\", \"Q325358\", \"Q168565\", \"Q18543139\", \"Q11606300\",\n",
    "                    \"Q2175765\", \"Q2298537\"]\n",
    "\n",
    "for i, row in britdf.iterrows():\n",
    "    if type(row[\"instance_of\"]) == str:\n",
    "        wkdtcl = ast.literal_eval(row[\"instance_of\"])\n",
    "        if any(x in wkdtcl for x in stn_wkdt_classes):\n",
    "            if not row[\"wikidata_id\"] in station_altnames:\n",
    "                stationgaz = pd.concat([stationgaz, wkgazetteer[wkgazetteer[\"wkid\"] == row[\"wikidata_id\"]]])\n",
    "                \n",
    "stationgaz = stationgaz[stationgaz['altname'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationgaz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most railway stations end with \"railway station\", but Quick's takes it for\n",
    "# granted that they are railway stations, so it just says \"Currie\" for \"Currie\n",
    "# railway station\". Therefore, we add new alternate names without rail keywords.\n",
    "re_station = r\"(.*)\\b(([Rr]ailw[ae]y [Ss]tation)|([Bb]us [Ss]tation)|([Uu]nderground [Ss]tation)|([Tt]ram [Ss]top)|([Hh]alt)|([Ss]top))((\\, .*)|( \\(.*))?$\"\n",
    "re_nostation = r\".*\\b(([Pp]olice [Ss]tation)|([Pp]ower [Ss]tation)|([Ll]ifeboat [Ss]tation)|([Pp]umping [Ss]tation)|([Tt]ransmitting [Ss]tation)).*$\"\n",
    "\n",
    "# stationgaz = pd.DataFrame()\n",
    "for i, row in stationgaz.iterrows():\n",
    "    if re.match(re_station, row[\"altname\"]) and not re.match(re_nostation, row[\"altname\"]):\n",
    "        newaltname = re.sub(re_station, r\"\\1\", row[\"altname\"])\n",
    "        if newaltname:\n",
    "            stationgaz = stationgaz.append(pd.Series([row[\"wkid\"], newaltname, \"processed\", row[\"lat\"], row[\"lon\"]], index=stationgaz.columns), ignore_index=True)\n",
    "\n",
    "stationgaz = stationgaz.drop_duplicates(subset = ['wkid', 'altname'])\n",
    "stationgaz = stationgaz[stationgaz['altname'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationgaz.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationgaz = stationgaz.drop_duplicates(subset = ['wkid', 'altname'])\n",
    "stationgaz.to_pickle(\"../toponym_matching/gazetteers/stnwikidata_gazetteer.pkl\")\n",
    "unique_placenames_array = list(set(list(np.array(stationgaz[\"altname\"]))))\n",
    "format_for_candranker(\"../toponym_matching/gazetteers/stnwikidata_candidates\", unique_placenames_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stationgaz.wkid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "britdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37deezy)",
   "language": "python",
   "name": "py37deezy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
