{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Wikidata candidates\n",
    "\n",
    "Two main outputs from this notebook:\n",
    "- [x] Generate a altname-centric British Wikidata gazetteer: `gazetteers/britwikidata_gazetteer.pkl`\n",
    "- [x] Generate the candidates (aka unique altnames) input file for candidate ranker: `gazetteers/britwikidata_candidates.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from collections import Counter\n",
    "from  itertools import chain\n",
    "import pydash\n",
    "import ast\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load British wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "britdf = pd.read_csv(\"british_isles.csv\", header=0, index_col=None, low_memory=False)\n",
    "britdf = britdf.drop(columns=['Unnamed: 0'])\n",
    "britdf['latitude'] = britdf['latitude'].astype(float)\n",
    "britdf['longitude'] = britdf['longitude'].astype(float)\n",
    "britdf = britdf[britdf['latitude'].notna()]\n",
    "britdf = britdf[britdf['longitude'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add geonames alternate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-07 13:34:08--  http://download.geonames.org/export/dump/alternateNamesV2.zip\n",
      "Resolving download.geonames.org (download.geonames.org)... 188.40.33.19\n",
      "Connecting to download.geonames.org (download.geonames.org)|188.40.33.19|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 161915121 (154M) [application/zip]\n",
      "Saving to: ‘alternateNamesV2.zip’\n",
      "\n",
      "alternateNamesV2.zi 100%[===================>] 154.41M  90.8MB/s    in 1.7s    \n",
      "\n",
      "2020-10-07 13:34:10 (90.8 MB/s) - ‘alternateNamesV2.zip’ saved [161915121/161915121]\n",
      "\n",
      "Archive:  alternateNamesV2.zip\n",
      "  inflating: iso-languagecodes.txt   \n",
      "  inflating: alternateNamesV2.txt    \n",
      "--2020-10-07 13:34:15--  http://download.geonames.org/export/dump/GB.zip\n",
      "Resolving download.geonames.org (download.geonames.org)... 188.40.33.19\n",
      "Connecting to download.geonames.org (download.geonames.org)|188.40.33.19|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2163500 (2.1M) [application/zip]\n",
      "Saving to: ‘GB.zip’\n",
      "\n",
      "GB.zip              100%[===================>]   2.06M  11.3MB/s    in 0.2s    \n",
      "\n",
      "2020-10-07 13:34:15 (11.3 MB/s) - ‘GB.zip’ saved [2163500/2163500]\n",
      "\n",
      "Archive:  GB.zip\n",
      "  inflating: readme.txt              \n",
      "  inflating: GB.txt                  \n",
      "--2020-10-07 13:34:16--  http://download.geonames.org/export/dump/IE.zip\n",
      "Resolving download.geonames.org (download.geonames.org)... 188.40.33.19\n",
      "Connecting to download.geonames.org (download.geonames.org)|188.40.33.19|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 743078 (726K) [application/zip]\n",
      "Saving to: ‘IE.zip’\n",
      "\n",
      "IE.zip              100%[===================>] 725.66K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2020-10-07 13:34:16 (5.61 MB/s) - ‘IE.zip’ saved [743078/743078]\n",
      "\n",
      "Archive:  IE.zip\n",
      "  inflating: readme.txt              \n",
      "  inflating: IE.txt                  \n"
     ]
    }
   ],
   "source": [
    "if not Path(\"/resources/geonames/alternateNamesV2.txt\").exists():\n",
    "    !wget http://download.geonames.org/export/dump/alternateNamesV2.zip\n",
    "    !unzip alternateNamesV2.zip\n",
    "    !rm alternateNamesV2.zip\n",
    "    !rm iso-languagecodes.txt\n",
    "    !mv alternateNamesV2.txt /resources/geonames/alternateNamesV2.txt\n",
    "    \n",
    "if not Path(\"/resources/geonames/GB.txt\").exists():\n",
    "    !wget http://download.geonames.org/export/dump/GB.zip\n",
    "    !unzip GB.zip\n",
    "    !rm readme.txt\n",
    "    !rm GB.zip\n",
    "    !mv GB.txt /resources/geonames/GB.txt\n",
    "    \n",
    "if not Path(\"/resources/geonames/IE.txt\").exists():\n",
    "    !wget http://download.geonames.org/export/dump/IE.zip\n",
    "    !unzip IE.zip\n",
    "    !rm readme.txt\n",
    "    !rm IE.zip\n",
    "    !mv IE.txt /resources/geonames/IE.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process alternate names table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoaltnames = pd.read_csv(\"/resources/geonames/alternateNamesV2.txt\", sep=\"\\t\", names=[\"alternateNameId\", \"geonameid\", \"isolanguage\", \"alternateName\", \"isPreferredName\", \"isShortName\", \"isColloquial\", \"isHistoric\", \"from\", \"to\"], index_col=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out alternate names that are actually pseudocodes:\n",
    "gn_pseudocodes = [\"post\", \"link\", \"iata\", \"icao\",\n",
    "                  \"faac\", \"tcid\", \"unlc\", \"abbr\",\n",
    "                  \"wkdt\", \"phon\", \"piny\", \"fr_1793\"] # Geonames pseucodes from here: https://www.geonames.org/manual.html\n",
    "\n",
    "geoaltnames = geoaltnames[~geoaltnames[\"isolanguage\"].isin(gn_pseudocodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoaltnames = geoaltnames.drop(columns=[\"alternateNameId\", \"isolanguage\", \"isPreferredName\", \"isShortName\", \"isColloquial\", \"isHistoric\", \"from\", \"to\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process GB and IE geonames tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country: GB (United Kingdom)\n",
    "gb_geonames = pd.read_csv(\"/resources/geonames/GB.txt\", sep=\"\\t\", names=[\"geonameid\", \"name\", \"asciiname\", \"alternatenames\", \"latitude\", \"longitude\", \"fclass\", \"fcode\", \"ccode\", \"cc2\", \"admin1\", \"admin2\", \"admin3\", \"admin4\", \"population\", \"elevation\", \"dem\", \"timezone\", \"moddate\"], index_col=None, low_memory=False)\n",
    "gb_geonames = gb_geonames.drop(columns=[\"alternatenames\", \"latitude\", \"longitude\", \"fclass\", \"fcode\", \"ccode\", \"cc2\", \"admin1\", \"admin2\", \"admin3\", \"admin4\", \"population\", \"elevation\", \"dem\", \"timezone\", \"moddate\"])\n",
    "gb_altnames = list(set(gb_geonames.groupby(['geonameid', 'name']).groups))\n",
    "gb_altnames.extend(list(set(gb_geonames.groupby(['geonameid', 'asciiname']).groups)))\n",
    "gb_altnames = list(set(gb_altnames))\n",
    "gb_geonames = pd.DataFrame(gb_altnames, columns = [\"geonameid\", \"alternateName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country: IE (Ireland)\n",
    "ie_geonames = pd.read_csv(\"/resources/geonames/IE.txt\", sep=\"\\t\", names=[\"geonameid\", \"name\", \"asciiname\", \"alternatenames\", \"latitude\", \"longitude\", \"fclass\", \"fcode\", \"ccode\", \"cc2\", \"admin1\", \"admin2\", \"admin3\", \"admin4\", \"population\", \"elevation\", \"dem\", \"timezone\", \"moddate\"], index_col=None, low_memory=False)\n",
    "ie_geonames = ie_geonames.drop(columns=[\"alternatenames\", \"latitude\", \"longitude\", \"fclass\", \"fcode\", \"ccode\", \"cc2\", \"admin1\", \"admin2\", \"admin3\", \"admin4\", \"population\", \"elevation\", \"dem\", \"timezone\", \"moddate\"])\n",
    "ie_altnames = list(set(ie_geonames.groupby(['geonameid', 'name']).groups))\n",
    "ie_altnames.extend(list(set(ie_geonames.groupby(['geonameid', 'asciiname']).groups)))\n",
    "ie_altnames = list(set(ie_altnames))\n",
    "ie_geonames = pd.DataFrame(ie_altnames, columns = [\"geonameid\", \"alternateName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate all altname dataframes and filter relevant rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geonames_altnames = pd.concat([geoaltnames, gb_geonames, ie_geonames], ignore_index=True)\n",
    "geonames_altnames = geonames_altnames.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out alternate names if they are not in Latin alphabet:\n",
    "def latin_alphabet(toponym):\n",
    "    latin_range = re.compile(u'[\\u0040-\\u007F\\u0080-\\u00FF\\u0100-\\u017F\\u0180-\\u024F]', flags=re.UNICODE)\n",
    "    if re.search(latin_range, toponym):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "geonames_altnames = geonames_altnames[geonames_altnames.apply(lambda x: latin_alphabet(x[\"alternateName\"]), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows that have a corresponding Wikidata entry\n",
    "def parse_geonames(geoIDs):\n",
    "    geonamesIDs = []\n",
    "    if type(geoIDs) == str:\n",
    "        geonamesIDs = ast.literal_eval(geoIDs)\n",
    "        geonamesIDs = [int(gn) for gn in geonamesIDs if type(gn) == str]\n",
    "    return geonamesIDs\n",
    "\n",
    "brit_geonameIDs = []\n",
    "for i, row in britdf.iterrows():\n",
    "    tmp_gnalt = parse_geonames(row[\"geonamesIDs\"])\n",
    "    if tmp_gnalt:\n",
    "        brit_geonameIDs.extend(tmp_gnalt)\n",
    "\n",
    "geonames_altnames = geonames_altnames[geonames_altnames[\"geonameid\"].isin(brit_geonameIDs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create altname-focused gazetteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_wikidata_altnames(elabel, aliases, nativelabel):\n",
    "    re_appo = r\"(.+)\\(.+\\)$\"\n",
    "    altnames = dict()\n",
    "    if type(elabel) == str:\n",
    "        if re.match(re_appo, elabel):\n",
    "            elabel = re.match(re_appo, elabel).group(1).strip()\n",
    "            elabel = re.sub(\",$\", \"\", elabel)\n",
    "        if not elabel in altnames:\n",
    "            altnames[elabel] = \"english_label\"\n",
    "    if type(aliases) == str:\n",
    "        aliases = ast.literal_eval(aliases)\n",
    "        for language in aliases:\n",
    "            for a in aliases[language]:\n",
    "                if not a in altnames:\n",
    "                    altnames[a] = \"wikidata_alias\"\n",
    "    if type(nativelabel) == str:\n",
    "        nlabel = ast.literal_eval(nativelabel)\n",
    "        for nl in nlabel:\n",
    "            if not nl in altnames:\n",
    "                altnames[nl] = \"native_label\"\n",
    "    return altnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_geonames_altnames(geonamesIDs, geoaltnames, altnames):\n",
    "    if type(geonamesIDs) == str:\n",
    "        geonamesIDs = ast.literal_eval(geonamesIDs)\n",
    "        for gid in geonamesIDs:\n",
    "            if type(gid) == str:\n",
    "                tmp_gndf = geoaltnames[geoaltnames[\"geonameid\"] == int(gid)]\n",
    "                if not tmp_gndf.empty:\n",
    "                    for i, row in tmp_gndf.iterrows():\n",
    "                        if not row[\"alternateName\"] in altnames:\n",
    "                            altnames[row[\"alternateName\"]] = \"geonames\"\n",
    "    return altnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_candranker(gazname, unique_placenames_array):\n",
    "    \"\"\"\n",
    "    This function returns the unique alternate names in a given gazetteer\n",
    "    in the format required by DeezyMatch candidate ranker.\"\"\"\n",
    "    with open(gazname + \".txt\", \"w\") as fw:\n",
    "        for pl in unique_placenames_array:\n",
    "            pl = pl.strip()\n",
    "            if pl:\n",
    "                pl = pl.replace('\"', \"\")\n",
    "                fw.write(pl.strip() + \"\\t0\\tfalse\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkid = []\n",
    "altname = []\n",
    "source = []\n",
    "lat = []\n",
    "lon = []\n",
    "for i, row in britdf.iterrows():\n",
    "    dAltnames = obtain_wikidata_altnames(row[\"english_label\"], row[\"alias_dict\"], row[\"nativelabel\"])\n",
    "    if dAltnames: # Entities without any alternate names are likely to be ghost entities, e.g. Q24663377\n",
    "        dAltnames = obtain_geonames_altnames(row[\"geonamesIDs\"], geonames_altnames, dAltnames)\n",
    "    for a in dAltnames:\n",
    "        if a:\n",
    "            if type(a) == str:\n",
    "                wkid.append(row[\"wikidata_id\"])\n",
    "                altname.append(a)\n",
    "                source.append(dAltnames[a])\n",
    "                lat.append(row[\"latitude\"])\n",
    "                lon.append(row[\"longitude\"])\n",
    "                \n",
    "wkgazetteer = pd.DataFrame()\n",
    "wkgazetteer[\"wkid\"] = wkid\n",
    "wkgazetteer[\"altname\"] = altname\n",
    "wkgazetteer[\"source\"] = source\n",
    "wkgazetteer[\"lat\"] = lat\n",
    "wkgazetteer[\"lon\"] = lon\n",
    "\n",
    "wkgazetteer = wkgazetteer.drop_duplicates(subset = ['wkid', 'altname'])\n",
    "wkgazetteer.to_pickle(\"../toponym_matching/gazetteers/britwikidata_gazetteer.pkl\")\n",
    "unique_placenames_array = list(set(list(np.array(wkgazetteer[\"altname\"]))))\n",
    "format_for_candranker(\"../toponym_matching/gazetteers/britwikidata_candidates\", unique_placenames_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(822161, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wkgazetteer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37deezy)",
   "language": "python",
   "name": "py37deezy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
