{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "import pandas as pd\n",
    "import pydash\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['en', 'cy', 'sco', 'gd', 'ga', 'kw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikidata(filename):\n",
    "    with bz2.open(filename, mode='rt') as f:\n",
    "        f.read(2) # skip first two bytes: \"{\\n\"\n",
    "        for line in f:\n",
    "            try:\n",
    "                yield json.loads(line.rstrip(',\\n'))\n",
    "            except json.decoder.JSONDecodeError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(record):\n",
    "    # Wikidata ID:\n",
    "    wikidata_id = record['id']\n",
    "\n",
    "    # ==========================================\n",
    "    # Place description and definition\n",
    "    # ==========================================\n",
    "\n",
    "    # Main label:\n",
    "    english_label = pydash.get(record, 'labels.en.value')\n",
    "\n",
    "    # Location is instance of\n",
    "    instance_of_dict = pydash.get(record, 'claims.P31')\n",
    "    instance_of = None\n",
    "    if instance_of_dict:\n",
    "        instance_of = [pydash.get(r, 'mainsnak.datavalue.value.id') for r in instance_of_dict]\n",
    "\n",
    "    # Descriptions in English:\n",
    "    description_set = set()\n",
    "    descriptions = pydash.get(record, 'descriptions')\n",
    "    for x in descriptions:\n",
    "        if x == 'en' or x.startswith('en-'):\n",
    "            description_set.add(pydash.get(descriptions[x], 'value'))\n",
    "\n",
    "    # Aliases and labels:\n",
    "    aliases = pydash.get(record, 'aliases')\n",
    "    labels = pydash.get(record, 'labels')\n",
    "    alias_dict = dict()\n",
    "    for x in aliases:\n",
    "        if x in languages or x.startswith('en-'):\n",
    "            for y in aliases[x]:\n",
    "                if \"value\" in y:\n",
    "                    if not y[\"value\"].isupper() and not y[\"value\"].islower() and any(x.isalpha() for x in y[\"value\"]):\n",
    "                        if x in alias_dict:\n",
    "                            if not y[\"value\"] in alias_dict[x]:\n",
    "                                alias_dict[x].append(y[\"value\"])\n",
    "                        else:\n",
    "                            alias_dict[x] = [y[\"value\"]]\n",
    "    for x in labels:\n",
    "        if x in languages or x.startswith('en-'):\n",
    "            if \"value\" in labels[x]:\n",
    "                if not labels[x][\"value\"].isupper() and not labels[x][\"value\"].islower() and any(z.isalpha() for z in labels[x][\"value\"]):\n",
    "                    if x in alias_dict:\n",
    "                        if not labels[x][\"value\"] in alias_dict[x]:\n",
    "                            alias_dict[x].append(labels[x][\"value\"])\n",
    "                    else:\n",
    "                        alias_dict[x] = [labels[x][\"value\"]]\n",
    "\n",
    "    # Native label\n",
    "    nativelabel_dict = pydash.get(record, 'claims.P1705')\n",
    "    nativelabel = None\n",
    "    if nativelabel_dict:\n",
    "        nativelabel = [pydash.get(c, 'mainsnak.datavalue.value.text') for c in nativelabel_dict]\n",
    "\n",
    "    # ==========================================\n",
    "    # Geographic and demographic information\n",
    "    # ==========================================\n",
    "\n",
    "    # Population at: dictionary of year-population pairs\n",
    "    population_dump = pydash.get(record, 'claims.P1082')\n",
    "    population_dict = dict()\n",
    "    if population_dump:\n",
    "        for ppl in population_dump:\n",
    "            pop_amount = pydash.get(ppl, 'mainsnak.datavalue.value.amount')\n",
    "            pop_time = pydash.get(ppl, 'qualifiers.P585[0].datavalue.value.time')\n",
    "            pop_time = \"UNKNOWN\" if not pop_time else pop_time\n",
    "            population_dict[pop_time] = pop_amount\n",
    "\n",
    "    # Area of location\n",
    "    dict_area_units = {'Q712226' : 'square kilometre',\n",
    "               'Q2737347': 'square millimetre',\n",
    "               'Q2489298': 'square centimetre',\n",
    "               'Q35852': 'hectare',\n",
    "               'Q185078': 'are',\n",
    "               'Q25343': 'square metre'}\n",
    "\n",
    "    area_loc = pydash.get(record, 'claims.P2046[0].mainsnak.datavalue.value')\n",
    "    area = None\n",
    "    if area_loc:\n",
    "        try:\n",
    "            if area_loc.get(\"unit\"):\n",
    "                area = (area_loc.get(\"amount\"), dict_area_units.get(area_loc.get(\"unit\").split(\"/\")[-1]))\n",
    "        except:\n",
    "            area = None\n",
    "\n",
    "    # ==========================================\n",
    "    # Historical information\n",
    "    # ==========================================\n",
    "\n",
    "    # Historical counties\n",
    "    hcounties_dict = pydash.get(record, 'claims.P7959')\n",
    "    hcounties = []\n",
    "    if hcounties_dict:\n",
    "        hcounties = [pydash.get(hc, 'mainsnak.datavalue.value.id') for hc in hcounties_dict]\n",
    "\n",
    "    # Date of official opening (e.g. https://www.wikidata.org/wiki/Q2011)\n",
    "    date_opening = pydash.get(record, 'claims.P1619[0].mainsnak.datavalue.value.time')\n",
    "\n",
    "    # Date of official closing\n",
    "    date_closing = pydash.get(record, 'claims.P3999[0].mainsnak.datavalue.value.time')\n",
    "\n",
    "    # Inception: date or point in time when the subject came into existence as defined\n",
    "    inception_date = pydash.get(record, 'claims.P571[0].mainsnak.datavalue.value.time')\n",
    "\n",
    "    # Dissolved, abolished or demolished: point in time at which the subject ceased to exist\n",
    "    dissolved_date = pydash.get(record, 'claims.P576[0].mainsnak.datavalue.value.time')\n",
    "\n",
    "    # Follows...: immediately prior item in a series of which the subject is a part: e.g. Vanuatu follows New Hebrides\n",
    "    follows_dict = pydash.get(record, 'claims.P155')\n",
    "    follows = []\n",
    "    if follows_dict:\n",
    "        for f in follows_dict:\n",
    "            follows.append(pydash.get(f, 'mainsnak.datavalue.value.id'))\n",
    "\n",
    "    # Replaces...: item replaced: e.g. New Hebrides is replaced by \n",
    "    replaces_dict = pydash.get(record, 'claims.P1365')\n",
    "    replaces = []\n",
    "    if replaces_dict:\n",
    "        for r in replaces_dict:\n",
    "            replaces.append(pydash.get(r, 'mainsnak.datavalue.value.id'))\n",
    "\n",
    "    # ==========================================\n",
    "    # Neighbouring or part-of locations\n",
    "    # ==========================================\n",
    "\n",
    "    # Located in adminitrative territorial entities (Wikidata ID)\n",
    "    adm_regions_dict = pydash.get(record, 'claims.P131')\n",
    "    adm_regions = dict()\n",
    "    if adm_regions_dict:\n",
    "        for r in adm_regions_dict:\n",
    "            regname = pydash.get(r, 'mainsnak.datavalue.value.id')\n",
    "            if regname:\n",
    "                entity_start_time = pydash.get(r, 'qualifiers.P580[0].datavalue.value.time')\n",
    "                entity_end_time = pydash.get(r, 'qualifiers.P582[0].datavalue.value.time')\n",
    "                adm_regions[regname] = (entity_start_time, entity_end_time)\n",
    "\n",
    "    # Country: sovereign state of this item\n",
    "    country_dict = pydash.get(record, 'claims.P17')\n",
    "    countries = dict()\n",
    "    if country_dict:\n",
    "        for r in country_dict:\n",
    "            countryname = pydash.get(r, 'mainsnak.datavalue.value.id')\n",
    "            if countryname:\n",
    "                entity_start_time = pydash.get(r, 'qualifiers.P580[0].datavalue.value.time')\n",
    "                entity_end_time = pydash.get(r, 'qualifiers.P582[0].datavalue.value.time')\n",
    "                countries[countryname] = (entity_start_time, entity_end_time)\n",
    "\n",
    "    # Continents (Wikidata ID)\n",
    "    continent_dict = pydash.get(record, 'claims.P30')\n",
    "    continents = None\n",
    "    if continent_dict:\n",
    "        continents = [pydash.get(r, 'mainsnak.datavalue.value.id') for r in continent_dict]\n",
    "\n",
    "    # Location is capital of\n",
    "    capital_of_dict = pydash.get(record, 'claims.P1376')\n",
    "    capital_of = None\n",
    "    if capital_of_dict:\n",
    "        capital_of = [pydash.get(r, 'mainsnak.datavalue.value.id') for r in capital_of_dict]\n",
    "\n",
    "    # Shares border with:\n",
    "    shares_border_dict = pydash.get(record, 'claims.P47')\n",
    "    borders = []\n",
    "    if shares_border_dict:\n",
    "        borders = [pydash.get(t, 'mainsnak.datavalue.value.id') for t in shares_border_dict]\n",
    "\n",
    "    # Nearby waterbodies (Wikidata ID)\n",
    "    near_water_dict = pydash.get(record, 'claims.P206')\n",
    "    near_water = None\n",
    "    if near_water_dict:\n",
    "        near_water = [pydash.get(r, 'mainsnak.datavalue.value.id') for r in near_water_dict]\n",
    "\n",
    "    # ==========================================\n",
    "    # Coordinates\n",
    "    # ==========================================\n",
    "\n",
    "    # Latitude and longitude:\n",
    "    latitude = pydash.get(record, 'claims.P625[0].mainsnak.datavalue.value.latitude')\n",
    "    longitude = pydash.get(record, 'claims.P625[0].mainsnak.datavalue.value.longitude')\n",
    "    if latitude and longitude:\n",
    "        latitude = round(latitude, 6)\n",
    "        longitude = round(longitude, 6)\n",
    "\n",
    "    # ==========================================\n",
    "    # External data resources IDs\n",
    "    # ==========================================\n",
    "\n",
    "    # English Wikipedia title:\n",
    "    wikititle = pydash.get(record, 'sitelinks.enwiki.title')\n",
    "\n",
    "    # Geonames ID\n",
    "    geonamesID_dict = pydash.get(record, 'claims.P1566')\n",
    "    geonamesIDs = None\n",
    "    if geonamesID_dict:\n",
    "        geonamesIDs = [pydash.get(gn, 'mainsnak.datavalue.value') for gn in geonamesID_dict]\n",
    "\n",
    "    # TOID: TOpographic IDentifier assigned by the Ordnance Survey to identify a feature in Great Britain\n",
    "    toID_dict = pydash.get(record, 'claims.P3120')\n",
    "    toIDs = None\n",
    "    if toID_dict:\n",
    "        toIDs = [pydash.get(t, 'mainsnak.datavalue.value') for t in toID_dict]\n",
    "\n",
    "    # British History Online VCH ID: identifier of a place, in the British History Online digitisation of the Victoria County History\n",
    "    vchID_dict = pydash.get(record, 'claims.P3628')\n",
    "    vchIDs = None\n",
    "    if vchID_dict:\n",
    "        vchIDs = [pydash.get(t, 'mainsnak.datavalue.value') for t in vchID_dict]\n",
    "\n",
    "    # Vision of Britain place ID: identifier of a place\n",
    "    vob_placeID_dict = pydash.get(record, 'claims.P3616')\n",
    "    vob_placeIDs = None\n",
    "    if vob_placeID_dict:\n",
    "        vob_placeIDs = [pydash.get(vobid, 'mainsnak.datavalue.value') for vobid in vob_placeID_dict]\n",
    "\n",
    "    # Vision of Britain unit ID: identifier of an administrative unit\n",
    "    vob_unitID_dict = pydash.get(record, 'claims.P3615')\n",
    "    vob_unitIDs = None\n",
    "    if vob_unitID_dict:\n",
    "        vob_unitIDs = dict()\n",
    "        for vobid in vob_unitID_dict:\n",
    "            unit_id = pydash.get(vobid, 'mainsnak.datavalue.value')\n",
    "            parish_name = pydash.get(vobid, 'qualifiers.P1810[0].datavalue.value')\n",
    "            vob_unitIDs[unit_id] = parish_name\n",
    "\n",
    "    # Identifier for a place in the Historical Gazetteer of England's Place Names website\n",
    "    epns_dict = pydash.get(record, 'claims.P3627')\n",
    "    epns = None\n",
    "    if epns_dict:\n",
    "        epns = [pydash.get(p, 'mainsnak.datavalue.value') for p in epns_dict]\n",
    "\n",
    "    # OS grid reference (Wikidata ID)\n",
    "    os_grid_ref = pydash.get(record, 'claims.P613[0].mainsnak.datavalue.value')\n",
    "\n",
    "    # ==========================================\n",
    "    # Street-related properties\n",
    "    # ==========================================\n",
    "\n",
    "    # Street connects with\n",
    "    connectswith_dict = pydash.get(record, 'claims.P2789')\n",
    "    connectswith = None\n",
    "    if connectswith_dict:\n",
    "        connectswith = [pydash.get(c, 'mainsnak.datavalue.value.id') for c in connectswith_dict]\n",
    "\n",
    "    # Street address\n",
    "    street_address = pydash.get(record, 'claims.P6375[0].mainsnak.datavalue.value.text')\n",
    "\n",
    "    # ==========================================\n",
    "    # Rail-related properties\n",
    "    # ==========================================\n",
    "\n",
    "    # Adjacent stations\n",
    "    adjacent_stations = None\n",
    "    adj_st_dump = pydash.get(record, 'claims.P197')\n",
    "    if adj_st_dump:\n",
    "        adjacent_stations = [pydash.get(adj_st, 'mainsnak.datavalue.value.id') for adj_st in adj_st_dump]\n",
    "\n",
    "    # UK railway station code\n",
    "    ukrailcode_dict = pydash.get(record, 'claims.P4755')\n",
    "    ukrailcode = None\n",
    "    if ukrailcode_dict:\n",
    "        ukrailcode = [pydash.get(ukrid, 'mainsnak.datavalue.value') for ukrid in ukrailcode_dict]\n",
    "\n",
    "    # Connecting lines\n",
    "    connectline_dict = pydash.get(record, 'claims.P81')\n",
    "    connectline = None\n",
    "    if connectline_dict:\n",
    "        connectline = [pydash.get(conline, 'mainsnak.datavalue.value.id') for conline in connectline_dict]\n",
    "\n",
    "    # ==========================================\n",
    "    # Store records in a dictionary\n",
    "    # ==========================================\n",
    "    df_record = {'wikidata_id': wikidata_id, 'english_label': english_label, 'instance_of': instance_of, 'description_set': description_set, 'alias_dict': alias_dict, 'nativelabel': nativelabel, 'population_dict': population_dict, 'area': area, 'hcounties': hcounties, 'date_opening': date_opening, 'date_closing': date_closing, 'inception_date': inception_date, 'dissolved_date': dissolved_date, 'follows': follows, 'replaces': replaces, 'adm_regions': adm_regions, 'countries': countries, 'continents': continents, 'capital_of': capital_of, 'borders': borders, 'near_water': near_water, 'latitude': latitude, 'longitude': longitude, 'wikititle': wikititle, 'geonamesIDs': geonamesIDs, 'toIDs': toIDs, 'vchIDs': vchIDs, 'vob_placeIDs': vob_placeIDs, 'vob_unitIDs': vob_unitIDs, 'epns': epns, 'os_grid_ref': os_grid_ref, 'connectswith': connectswith, 'street_address': street_address, 'adjacent_stations': adjacent_stations, 'ukrailcode': ukrailcode, 'connectline': connectline}\n",
    "    return df_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse all WikiData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # ==========================================\n",
    "# # Parse all WikiData\n",
    "# # ==========================================\n",
    "\n",
    "# df_record_all = pd.DataFrame(columns=['wikidata_id', 'english_label', 'instance_of', 'description_set', 'alias_dict', 'nativelabel', 'population_dict', 'area', 'hcounties', 'date_opening', 'date_closing', 'inception_date', 'dissolved_date', 'follows', 'replaces', 'adm_regions', 'countries', 'continents', 'capital_of', 'borders', 'near_water', 'latitude', 'longitude', 'wikititle', 'geonamesIDs', 'toIDs', 'vchIDs', 'vob_placeIDs', 'vob_unitIDs', 'epns', 'os_grid_ref', 'connectswith', 'street_address', 'adjacent_stations', 'ukrailcode', 'connectline'])\n",
    "\n",
    "# header=True\n",
    "# i = 0\n",
    "# for record in tqdm(wikidata('/resources/wikidata/latest-all.json.bz2')):\n",
    "    \n",
    "#     # Only extract items with geographical coordinates (P625)\n",
    "#     if pydash.has(record, 'claims.P625'):\n",
    "        \n",
    "#         # ==========================================\n",
    "#         # Store records in a csv\n",
    "#         # ==========================================\n",
    "#         df_record = parse_record(record)\n",
    "#         df_record_all = df_record_all.append(df_record, ignore_index=True)\n",
    "#         i += 1\n",
    "#         if (i % 5000 == 0):\n",
    "#             pd.DataFrame.to_csv(df_record_all, path_or_buf='extracted/till_'+record['id']+'_item.csv')\n",
    "#             print('i = '+str(i)+' item '+record['id']+'  Done!')\n",
    "#             print('CSV exported')\n",
    "#             df_record_all = pd.DataFrame(columns=['wikidata_id', 'english_label', 'instance_of', 'description_set', 'alias_dict', 'nativelabel', 'population_dict', 'area', 'hcounties', 'date_opening', 'date_closing', 'inception_date', 'dissolved_date', 'follows', 'replaces', 'adm_regions', 'countries', 'continents', 'capital_of', 'borders', 'near_water', 'latitude', 'longitude', 'wikititle', 'geonamesIDs', 'toIDs', 'vchIDs', 'vob_placeIDs', 'vob_unitIDs', 'epns', 'os_grid_ref', 'connectswith', 'street_address', 'adjacent_stations', 'ukrailcode', 'connectline'])\n",
    "#         else:\n",
    "#             continue\n",
    "            \n",
    "# pd.DataFrame.to_csv(df_record_all, path_or_buf='extracted/final_csv_till_'+record['id']+'_item.csv')\n",
    "# print('i = '+str(i)+' item '+record['id']+'  Done!')\n",
    "# print('All items finished, final CSV exported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse just one Wikidata record (from client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Parse a given WikiData record\n",
    "# ==========================================\n",
    "from wikidata.client import Client\n",
    "client = Client()\n",
    "entity = client.get('Q2269429', load=True)\n",
    "record = entity.__dict__['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wikidata_id': 'Q2269429',\n",
       " 'english_label': 'York railway station',\n",
       " 'instance_of': ['Q55488'],\n",
       " 'description_set': {'main-line railway station serving the city of York, England',\n",
       "  'railway station in the United Kingdom'},\n",
       " 'alias_dict': {'cy': ['Gorsaf reilffordd Efrog'],\n",
       "  'en': ['York railway station'],\n",
       "  'en-ca': ['York railway station'],\n",
       "  'en-gb': ['York railway station']},\n",
       " 'nativelabel': None,\n",
       " 'population_dict': {},\n",
       " 'area': None,\n",
       " 'hcounties': ['Q163'],\n",
       " 'date_opening': '+1877-06-25T00:00:00Z',\n",
       " 'date_closing': None,\n",
       " 'inception_date': None,\n",
       " 'dissolved_date': None,\n",
       " 'follows': [],\n",
       " 'replaces': [],\n",
       " 'adm_regions': {'Q20986421': (None, None), 'Q23086': (None, None)},\n",
       " 'countries': {'Q145': (None, None)},\n",
       " 'continents': None,\n",
       " 'capital_of': None,\n",
       " 'borders': [],\n",
       " 'near_water': None,\n",
       " 'latitude': 53.9583,\n",
       " 'longitude': -1.093,\n",
       " 'wikititle': 'York railway station',\n",
       " 'geonamesIDs': ['6953968'],\n",
       " 'toIDs': None,\n",
       " 'vchIDs': None,\n",
       " 'vob_placeIDs': None,\n",
       " 'vob_unitIDs': None,\n",
       " 'epns': None,\n",
       " 'os_grid_ref': 'SE596517',\n",
       " 'connectswith': None,\n",
       " 'street_address': None,\n",
       " 'adjacent_stations': ['Q2565782',\n",
       "  'Q2065298',\n",
       "  'Q2424788',\n",
       "  'Q951589',\n",
       "  'Q7229551'],\n",
       " 'ukrailcode': ['YRK'],\n",
       " 'connectline': ['Q672271', 'Q5247012', 'Q5666416', 'Q5936045', 'Q667860']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_record(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate resulting csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = r\"extracted/\"\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>english_label</th>\n",
       "      <th>instance_of</th>\n",
       "      <th>description_set</th>\n",
       "      <th>alias_dict</th>\n",
       "      <th>nativelabel</th>\n",
       "      <th>population_dict</th>\n",
       "      <th>area</th>\n",
       "      <th>hcounties</th>\n",
       "      <th>date_opening</th>\n",
       "      <th>date_closing</th>\n",
       "      <th>inception_date</th>\n",
       "      <th>dissolved_date</th>\n",
       "      <th>follows</th>\n",
       "      <th>replaces</th>\n",
       "      <th>adm_regions</th>\n",
       "      <th>countries</th>\n",
       "      <th>continents</th>\n",
       "      <th>capital_of</th>\n",
       "      <th>borders</th>\n",
       "      <th>near_water</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>wikititle</th>\n",
       "      <th>geonamesIDs</th>\n",
       "      <th>toIDs</th>\n",
       "      <th>vchIDs</th>\n",
       "      <th>vob_placeIDs</th>\n",
       "      <th>vob_unitIDs</th>\n",
       "      <th>epns</th>\n",
       "      <th>os_grid_ref</th>\n",
       "      <th>connectswith</th>\n",
       "      <th>street_address</th>\n",
       "      <th>adjacent_stations</th>\n",
       "      <th>ukrailcode</th>\n",
       "      <th>connectline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Q31</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>['Q3624078', 'Q43702', 'Q6256', 'Q20181813', '...</td>\n",
       "      <td>{'country in Europe', 'constitutional monarchy...</td>\n",
       "      <td>{'en-gb': ['Southern Netherlands', 'Belgium'],...</td>\n",
       "      <td>['Koninkrijk België', 'Royaume de Belgique', '...</td>\n",
       "      <td>{'+2014-01-01T00:00:00Z': '+11150516', '+2013-...</td>\n",
       "      <td>('+30528', 'square kilometre')</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+1830-10-04T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Q15864']</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Q31': (None, None)}</td>\n",
       "      <td>['Q46']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Q183', 'Q32', 'Q142', 'Q55', 'Q29999']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.641111</td>\n",
       "      <td>4.668056</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>['2802361']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Q45</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>['Q3624078', 'Q6256', 'Q20181813']</td>\n",
       "      <td>{'country in Europe', 'sovereign state in sout...</td>\n",
       "      <td>{'en': ['Portuguese Republic', 'Portugal'], 'e...</td>\n",
       "      <td>['República Portuguesa', 'Portugal']</td>\n",
       "      <td>{'+1960-00-00T00:00:00Z': '+8857716', '+1961-0...</td>\n",
       "      <td>('+92212', 'square kilometre')</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+1143-10-05T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Q45670']</td>\n",
       "      <td>['Q200464']</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Q45': (None, None)}</td>\n",
       "      <td>['Q46']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Q29', 'Q5739']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.700000</td>\n",
       "      <td>-9.183333</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>['2264397']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Q51</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>['Q5107', 'Q82794']</td>\n",
       "      <td>{'polar continent'}</td>\n",
       "      <td>{'ga': ['An Antartaice', 'Antartaice'], 'sco':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'+2009-00-00T00:00:00Z': '+4400'}</td>\n",
       "      <td>('+14000000', 'square kilometre')</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'Q21590062': (None, None)}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Antarctica</td>\n",
       "      <td>['6255152']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Q148</td>\n",
       "      <td>People's Republic of China</td>\n",
       "      <td>['Q3624078', 'Q842112', 'Q859563', 'Q1520223',...</td>\n",
       "      <td>{'country in East Asia', 'sovereign state in E...</td>\n",
       "      <td>{'en': ['China', 'PR China', 'Communist China'...</td>\n",
       "      <td>['中华人民共和国', '中華人民共和國']</td>\n",
       "      <td>{'+2012-07-01T00:00:00Z': '+1375198619', '+201...</td>\n",
       "      <td>('+9596961', 'square kilometre')</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+1949-10-01T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Q13426199', 'Q4120908']</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Q148': (None, None)}</td>\n",
       "      <td>['Q48']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Q711', 'Q232', 'Q813', 'Q863', 'Q843', 'Q668...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.844722</td>\n",
       "      <td>103.451944</td>\n",
       "      <td>China</td>\n",
       "      <td>['1814991']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Q155</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>['Q3624078', 'Q859563', 'Q4209223', 'Q6256']</td>\n",
       "      <td>{'country in South America'}</td>\n",
       "      <td>{'en': ['Federative Republic of Brazil', 'Bras...</td>\n",
       "      <td>['República Federativa do Brasil']</td>\n",
       "      <td>{'+2015-07-00T00:00:00Z': '+202656788', '+1960...</td>\n",
       "      <td>('+8515767', 'square kilometre')</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+1822-01-01T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Q217230', 'Q2088324']</td>\n",
       "      <td>['Q217230']</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'Q155': ('+1822-00-00T00:00:00Z', None), 'Q20...</td>\n",
       "      <td>['Q18']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Q414', 'Q750', 'Q3769', 'Q734', 'Q733', 'Q41...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>['3469034']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 wikidata_id               english_label  \\\n",
       "0           0         Q31                     Belgium   \n",
       "1           1         Q45                    Portugal   \n",
       "2           2         Q51                  Antarctica   \n",
       "3           3        Q148  People's Republic of China   \n",
       "4           4        Q155                      Brazil   \n",
       "\n",
       "                                         instance_of  \\\n",
       "0  ['Q3624078', 'Q43702', 'Q6256', 'Q20181813', '...   \n",
       "1                 ['Q3624078', 'Q6256', 'Q20181813']   \n",
       "2                                ['Q5107', 'Q82794']   \n",
       "3  ['Q3624078', 'Q842112', 'Q859563', 'Q1520223',...   \n",
       "4       ['Q3624078', 'Q859563', 'Q4209223', 'Q6256']   \n",
       "\n",
       "                                     description_set  \\\n",
       "0  {'country in Europe', 'constitutional monarchy...   \n",
       "1  {'country in Europe', 'sovereign state in sout...   \n",
       "2                                {'polar continent'}   \n",
       "3  {'country in East Asia', 'sovereign state in E...   \n",
       "4                       {'country in South America'}   \n",
       "\n",
       "                                          alias_dict  \\\n",
       "0  {'en-gb': ['Southern Netherlands', 'Belgium'],...   \n",
       "1  {'en': ['Portuguese Republic', 'Portugal'], 'e...   \n",
       "2  {'ga': ['An Antartaice', 'Antartaice'], 'sco':...   \n",
       "3  {'en': ['China', 'PR China', 'Communist China'...   \n",
       "4  {'en': ['Federative Republic of Brazil', 'Bras...   \n",
       "\n",
       "                                         nativelabel  \\\n",
       "0  ['Koninkrijk België', 'Royaume de Belgique', '...   \n",
       "1               ['República Portuguesa', 'Portugal']   \n",
       "2                                                NaN   \n",
       "3                             ['中华人民共和国', '中華人民共和國']   \n",
       "4                 ['República Federativa do Brasil']   \n",
       "\n",
       "                                     population_dict  \\\n",
       "0  {'+2014-01-01T00:00:00Z': '+11150516', '+2013-...   \n",
       "1  {'+1960-00-00T00:00:00Z': '+8857716', '+1961-0...   \n",
       "2                 {'+2009-00-00T00:00:00Z': '+4400'}   \n",
       "3  {'+2012-07-01T00:00:00Z': '+1375198619', '+201...   \n",
       "4  {'+2015-07-00T00:00:00Z': '+202656788', '+1960...   \n",
       "\n",
       "                                area hcounties date_opening date_closing  \\\n",
       "0     ('+30528', 'square kilometre')        []          NaN          NaN   \n",
       "1     ('+92212', 'square kilometre')        []          NaN          NaN   \n",
       "2  ('+14000000', 'square kilometre')        []          NaN          NaN   \n",
       "3   ('+9596961', 'square kilometre')        []          NaN          NaN   \n",
       "4   ('+8515767', 'square kilometre')        []          NaN          NaN   \n",
       "\n",
       "          inception_date dissolved_date                  follows  \\\n",
       "0  +1830-10-04T00:00:00Z            NaN                       []   \n",
       "1  +1143-10-05T00:00:00Z            NaN               ['Q45670']   \n",
       "2                    NaN            NaN                       []   \n",
       "3  +1949-10-01T00:00:00Z            NaN                       []   \n",
       "4  +1822-01-01T00:00:00Z            NaN  ['Q217230', 'Q2088324']   \n",
       "\n",
       "                    replaces                  adm_regions  \\\n",
       "0                 ['Q15864']                           {}   \n",
       "1                ['Q200464']                           {}   \n",
       "2                         []  {'Q21590062': (None, None)}   \n",
       "3  ['Q13426199', 'Q4120908']                           {}   \n",
       "4                ['Q217230']                           {}   \n",
       "\n",
       "                                           countries continents capital_of  \\\n",
       "0                              {'Q31': (None, None)}    ['Q46']        NaN   \n",
       "1                              {'Q45': (None, None)}    ['Q46']        NaN   \n",
       "2                                                 {}        NaN        NaN   \n",
       "3                             {'Q148': (None, None)}    ['Q48']        NaN   \n",
       "4  {'Q155': ('+1822-00-00T00:00:00Z', None), 'Q20...    ['Q18']        NaN   \n",
       "\n",
       "                                             borders near_water   latitude  \\\n",
       "0           ['Q183', 'Q32', 'Q142', 'Q55', 'Q29999']        NaN  50.641111   \n",
       "1                                   ['Q29', 'Q5739']        NaN  38.700000   \n",
       "2                                                 []        NaN -90.000000   \n",
       "3  ['Q711', 'Q232', 'Q813', 'Q863', 'Q843', 'Q668...        NaN  35.844722   \n",
       "4  ['Q414', 'Q750', 'Q3769', 'Q734', 'Q733', 'Q41...        NaN -14.000000   \n",
       "\n",
       "    longitude   wikititle  geonamesIDs toIDs vchIDs vob_placeIDs vob_unitIDs  \\\n",
       "0    4.668056     Belgium  ['2802361']   NaN    NaN          NaN         NaN   \n",
       "1   -9.183333    Portugal  ['2264397']   NaN    NaN          NaN         NaN   \n",
       "2    0.000000  Antarctica  ['6255152']   NaN    NaN          NaN         NaN   \n",
       "3  103.451944       China  ['1814991']   NaN    NaN          NaN         NaN   \n",
       "4  -53.000000      Brazil  ['3469034']   NaN    NaN          NaN         NaN   \n",
       "\n",
       "   epns os_grid_ref connectswith street_address adjacent_stations ukrailcode  \\\n",
       "0   NaN         NaN          NaN            NaN               NaN        NaN   \n",
       "1   NaN         NaN          NaN            NaN               NaN        NaN   \n",
       "2   NaN         NaN          NaN            NaN               NaN        NaN   \n",
       "3   NaN         NaN          NaN            NaN               NaN        NaN   \n",
       "4   NaN         NaN          NaN            NaN               NaN        NaN   \n",
       "\n",
       "  connectline  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37deezy)",
   "language": "python",
   "name": "py37deezy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
