{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import pathlib\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, CharacterEmbeddings, FlairEmbeddings\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_webanno_format(wf):\n",
    "    \n",
    "    output_folder = \"webanno_annotations/formatted/\"\n",
    "    pathlib.Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "    wfilename = wf.split(\"/\")[-2].split(\".txt\")[0]\n",
    "    \n",
    "    with open(wf) as fr:\n",
    "        lines = fr.readlines()\n",
    "        \n",
    "    dTags = {\"alternate\\_name\": \"altname\",\n",
    "            \"closing\\_date\": \"closed\",\n",
    "            \"company\": \"company\",\n",
    "            \"opening\\_date\": \"opened\",\n",
    "            \"station\": \"station\",\n",
    "            \"station\\_in\": \"stationIn\",\n",
    "            \"station\\_near\": \"stationNear\"}\n",
    "\n",
    "    annotated = False # Flag: if there is no annotation in the file, we'll discard it\n",
    "    annotations = []\n",
    "    numbering = 0\n",
    "    for line in lines:\n",
    "        if not line.startswith(\"#\"):\n",
    "            line = line.strip()\n",
    "            line = line.split(\"\\t\")\n",
    "            tag = \"\"\n",
    "            if len(line) > 3:\n",
    "                token = line[2]\n",
    "                anntag = line[3].split(\"[\")[0]\n",
    "                if anntag in dTags.keys():\n",
    "                    annotated = True\n",
    "                    tag = dTags[anntag]\n",
    "                    if line[3].endswith(\"]\"):\n",
    "                        newnumber = str(line[3].split(\"]\")[0].split(\"[\")[1])\n",
    "                        if newnumber == numbering:\n",
    "                            tag = \"I-\" + tag\n",
    "                        else:\n",
    "                            tag = \"B-\" + tag\n",
    "                        numbering = newnumber\n",
    "                    else:\n",
    "                        tag = \"B-\" + tag\n",
    "                else:\n",
    "                    tag = \"O\"\n",
    "                annotations.append([token, tag])\n",
    "            elif len(line) > 2:\n",
    "                token = line[2]\n",
    "                annotations.append([token, \"O\"])\n",
    "        else:\n",
    "#             annotations.append([\"[SEP]\", \"O\"])\n",
    "            annotations.append(\"\")\n",
    "    \n",
    "    if annotated == True:\n",
    "        with open(output_folder + wfilename + \".tsv\", \"w\") as csv_file:\n",
    "            writer = csv.writer(csv_file, delimiter='\\t')\n",
    "            for a in annotations:\n",
    "                writer.writerow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse webanno annotations:\n",
    "for i in glob.glob(\"webanno_annotations/Quick_2021-01-06_0810/annotation/*/*.tsv\"):\n",
    "    parse_webanno_format(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, val, and test\n",
    "formatted_files = glob.glob(\"webanno_annotations/formatted/*\")\n",
    "train, val, test = np.split(formatted_files, [int(len(formatted_files)*0.6), int(len(formatted_files)*0.9)])\n",
    "    \n",
    "output_folder = \"webanno_annotations/datasets/\"\n",
    "pathlib.Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dSplits = {\"train\": train, \"val\": val, \"test\": test}\n",
    "\n",
    "for spl in dSplits:\n",
    "    with open(output_folder + spl + \".txt\", 'w') as outfile:\n",
    "        for fname in dSplits[spl]:\n",
    "            with open(fname) as infile:\n",
    "                outfile.write(infile.read())\n",
    "                outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FROM: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_6_CORPUS.md\n",
    "\n",
    "# define columns\n",
    "columns = {0: 'text', 1: 'tag'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = \"webanno_annotations/datasets/\"\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train.txt',\n",
    "                              test_file='test.txt',\n",
    "                              dev_file='val.txt')\n",
    "\n",
    "# get the corpus\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the tag dictionary from the corpus\n",
    "tag_type = 'tag'\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FROM: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md\n",
    "\n",
    "# initialize embeddings\n",
    "embedding_types = [\n",
    "\n",
    "    WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "#     CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "#     FlairEmbeddings('news-forward'),\n",
    "#     FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sequence tagger\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "trainer.train('models/example-tag',\n",
    "              learning_rate=0.05,\n",
    "              mini_batch_size=16,\n",
    "              max_epochs=50,\n",
    "              anneal_with_restarts=True,\n",
    "              patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"[[[STATION: FRONGOCH]]] [GW] op 1 November 1882 (N Wales Express 3 rd ) ; clo 4 January 1960 (RM March) .\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model you trained\n",
    "model = SequenceTagger.load('models/example-tag/best-model.pt')\n",
    "\n",
    "# create example sentence\n",
    "sentence = Sentence(s)\n",
    "\n",
    "# predict tags and print\n",
    "model.predict(sentence)\n",
    "\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37linked)",
   "language": "python",
   "name": "py37linked"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
