{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import re\n",
    "import json\n",
    "import collections\n",
    "from lxml import etree\n",
    "from xml.etree.ElementTree import XML\n",
    "from random import shuffle\n",
    "import pathlib\n",
    "import itertools\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "docxFileName = \"/resources/quick/quick_section4.docx\"\n",
    "docxZip = zipfile.ZipFile(docxFileName)\n",
    "documentXML = docxZip.read('word/document.xml')\n",
    "et = etree.XML(documentXML)\n",
    "ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "\n",
    "pathlib.Path('outputs/').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find main stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainstation = \"\"\n",
    "lowerstation = \"\"\n",
    "dText = dict()\n",
    "counter = 0\n",
    "for i, para in enumerate(et.xpath('//w:p', namespaces=ns)):\n",
    "    text = para.xpath('./w:r/w:t', namespaces=ns)\n",
    "    description = \" \".join([t.text for t in text])\n",
    "    mainstation, counter = utils.is_mainst(para, mainstation, counter, ns)\n",
    "    description = description.lstrip('\\x01').strip()\n",
    "    if description:\n",
    "        if (counter, mainstation) in dText:\n",
    "            dText[(counter, mainstation)].append(description)\n",
    "        else:\n",
    "            description = re.sub('^(' + re.escape(mainstation) + ')', '\\1', description).lstrip('\\x01').strip()\n",
    "            description = re.sub(r\" +\", \" \", description).lstrip('\\x01').strip()\n",
    "            if description:\n",
    "                dText[(counter, mainstation)] = [description]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index main stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStations = collections.OrderedDict(dText)\n",
    "\n",
    "indices = []\n",
    "stations = []\n",
    "descriptions = []\n",
    "for k in dStations:\n",
    "    indices.append(k[0])\n",
    "    stations.append(k[1])\n",
    "    descriptions.append(dStations[k])\n",
    "\n",
    "stationdf = pd.DataFrame(columns=[\"Index\", \"Station\", \"Description\"])\n",
    "stationdf[\"Index\"] = indices\n",
    "stationdf[\"Station\"] = stations\n",
    "stationdf[\"Description\"] = descriptions\n",
    "stationdf = stationdf.set_index(\"Index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect substations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stations = pd.DataFrame(columns=['station','type','description'])\n",
    "cols = ['MainId', 'MainStation', 'SubId', 'SubStation', 'Description']\n",
    "lst = []\n",
    "subInd = 0\n",
    "for i, row in stationdf.iterrows():\n",
    "    main_station = row[\"Station\"]\n",
    "    description = row[\"Description\"]\n",
    "    dSubstations, subInd = utils.process_decription(main_station, description, subInd)\n",
    "    for ss in dSubstations:\n",
    "        lst.append([i, main_station, ss[0], ss[1], dSubstations[ss]])\n",
    "subsdf = pd.DataFrame(lst, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming abbreviated substations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsdf['SubStFormatted'] = subsdf.apply(lambda row: utils.subst_rename(row[\"MainStation\"], row[\"SubStation\"]), axis = 1)\n",
    "subsdf = subsdf[[\"MainId\", \"SubId\", \"MainStation\", \"SubStation\", \"SubStFormatted\", \"Description\"]]\n",
    "subsdf.to_pickle('outputs/quicks_processed.pkl')\n",
    "subsdf.to_csv('outputs/quicks_processed.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting station names as required by DeezyMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_placenames_array = list(set(list(np.array(subsdf[\"MainStation\"]))))\n",
    "utils.format_for_candranker(\"../toponym_matching/toponyms/quicks_mainst_queries\", unique_placenames_array)\n",
    "\n",
    "unique_placenames_array = list(set(list(np.array(subsdf[\"SubStFormatted\"]))))\n",
    "utils.format_for_candranker(\"../toponym_matching/toponyms/quicks_subst_queries\", unique_placenames_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find disambiguators and companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsedf = subsdf.copy()\n",
    "parsedf[['Disambiguator', 'Companies', 'FirstCompanyWkdt', 'AltCompaniesWkdt']] = parsedf.apply(lambda row: pd.Series(list(utils.detect_companies(row[\"Description\"]))), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract map information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsedf[['LocsMaps', 'LocsMapsDescr']] = parsedf.apply(lambda row: pd.Series(list(utils.detect_mapsInfo(row[\"Description\"]))), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extact alternate and referenced railway stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedf[['Altnames', 'Referenced']] = parsedf.apply(lambda row: pd.Series(list(utils.detect_altnames(row[\"Description\"], row[\"MainStation\"], row[\"SubStFormatted\"]))), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture opening and closing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedf[['Opening', 'Closing']] = parsedf.apply(lambda row: pd.Series(list(utils.capture_dates(row[\"Description\"]))), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare altnames, refs and disambiguators as DeezyMatch queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.prepare_alt_queries(parsedf, \"Altnames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedf.to_pickle('outputs/quicks_parsed.pkl')\n",
    "parsedf.to_csv('outputs/quicks_parsed.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "source": [
    "### Create dev and test dataframes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv('resources/annotations.tsv', sep='\\t')\n",
    "df_dev = annotations[annotations[\"DevTest\"] == \"Dev\"]\n",
    "df_test = annotations[annotations[\"DevTest\"] == \"Test\"]\n",
    "\n",
    "df_test = pd.merge(df_test, parsedf, on=[\"MainId\", \"SubId\", \"MainStation\", \"SubStation\", \"SubStFormatted\", \"Description\"])\n",
    "df_dev = pd.merge(df_dev, parsedf, on=[\"MainId\", \"SubId\", \"MainStation\", \"SubStation\", \"SubStFormatted\", \"Description\"])\n",
    "\n",
    "df_dev.to_pickle('outputs/quicks_dev.pkl')\n",
    "df_dev.to_csv('outputs/quicks_dev.tsv', sep=\"\\t\", index=False)\n",
    "\n",
    "df_test.to_pickle('outputs/quicks_test.pkl')\n",
    "df_test.to_csv('outputs/quicks_test.tsv', sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}