{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import re\n",
    "import json\n",
    "import collections\n",
    "from lxml import etree\n",
    "from xml.etree.ElementTree import XML\n",
    "from random import shuffle\n",
    "import pathlib\n",
    "import itertools\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "docxFileName = \"../resources/quicks/quick_section4.docx\"\n",
    "docxZip = zipfile.ZipFile(docxFileName)\n",
    "documentXML = docxZip.read('word/document.xml')\n",
    "et = etree.XML(documentXML)\n",
    "ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using xpath to find main stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainstation = \"\"\n",
    "lowerstation = \"\"\n",
    "dText = dict()\n",
    "counter = 0\n",
    "for i, para in enumerate(et.xpath('//w:p', namespaces=ns)):\n",
    "    text = para.xpath('./w:r/w:t', namespaces=ns)\n",
    "    description = \" \".join([t.text for t in text])\n",
    "    mainstation, counter = utils.is_mainst(para, mainstation, counter, ns)\n",
    "    print(mainstation)\n",
    "    description = description.lstrip('\\x01').strip()\n",
    "    if description:\n",
    "        if (counter, mainstation) in dText:\n",
    "            dText[(counter, mainstation)].append(description)\n",
    "        else:\n",
    "            description = re.sub('^(' + re.escape(mainstation) + ')', '\\1', description).lstrip('\\x01').strip()\n",
    "            description = re.sub(r\" +\", \" \", description).lstrip('\\x01').strip()\n",
    "            if description:\n",
    "                dText[(counter, mainstation)] = [description]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing main stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStations = collections.OrderedDict(dText)\n",
    "\n",
    "indices = []\n",
    "stations = []\n",
    "descriptions = []\n",
    "for k in dStations:\n",
    "    indices.append(k[0])\n",
    "    stations.append(k[1])\n",
    "    descriptions.append(dStations[k])\n",
    "\n",
    "stationdf = pd.DataFrame(columns=[\"Index\", \"Station\", \"Description\"])\n",
    "stationdf[\"Index\"] = indices\n",
    "stationdf[\"Station\"] = stations\n",
    "stationdf[\"Description\"] = descriptions\n",
    "stationdf = stationdf.set_index(\"Index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regex to find substations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stations = pd.DataFrame(columns=['station','type','description'])\n",
    "cols = ['MainId', 'MainStation', 'SubId', 'SubStation', 'Description']\n",
    "lst = []\n",
    "subInd = 0\n",
    "for i, row in stationdf.iterrows():\n",
    "    main_station = row[\"Station\"]\n",
    "    description = row[\"Description\"]\n",
    "    dSubstations, subInd = utils.process_decription(main_station, description, subInd)\n",
    "    for ss in dSubstations:\n",
    "        lst.append([i, main_station, ss[0], ss[1], dSubstations[ss]])\n",
    "subsdf = pd.DataFrame(lst, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming abbreviated substations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsdf['SubStFormatted'] = subsdf.apply(lambda row: utils.subst_rename(row[\"MainStation\"], row[\"SubStation\"]), axis = 1)\n",
    "subsdf = subsdf[[\"MainId\", \"SubId\", \"MainStation\", \"SubStation\", \"SubStFormatted\", \"Description\"]]\n",
    "subsdf.to_pickle('quicks_processed.pkl')\n",
    "subsdf.to_csv('quicks_processed.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting station names as required by DeezyMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_placenames_array = list(set(list(np.array(subsdf[\"MainStation\"]))))\n",
    "utils.format_for_candranker(\"../toponym_matching/toponyms/quicks_mainst_queries\", unique_placenames_array)\n",
    "\n",
    "unique_placenames_array = list(set(list(np.array(subsdf[\"SubStFormatted\"]))))\n",
    "utils.format_for_candranker(\"../toponym_matching/toponyms/quicks_subst_queries\", unique_placenames_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37deezy)",
   "language": "python",
   "name": "py37deezy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
