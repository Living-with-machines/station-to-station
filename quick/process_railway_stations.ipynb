{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import re\n",
    "import json\n",
    "import collections\n",
    "from lxml import etree\n",
    "from xml.etree.ElementTree import XML\n",
    "from random import shuffle\n",
    "import pathlib\n",
    "import itertools\n",
    "import string\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "\n",
    "docxFileName = \"../resources/quicks/quick_section4.docx\"\n",
    "docxZip = zipfile.ZipFile(docxFileName)\n",
    "documentXML = docxZip.read('word/document.xml')\n",
    "et = etree.XML(documentXML)\n",
    "ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using xpath to find main stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainstation_xpath = './w:r[not(preceding-sibling::w:r//w:t)][not(w:rPr/w:sz[@w:val=\\\"16\\\"])][..//w:b[not(@w:val=\\\"0\\\")]]/w:t[1]'\n",
    "mainstation_xpath2 = './w:r[not(preceding-sibling::w:r//w:t)][not(w:rPr/w:sz[@w:val=\\\"16\\\"])][../w:pPr[w:pStyle]/w:rPr/w:b[@w:val=\\\"0\\\"]]/w:t[1]'\n",
    "mainstation_xpath3 = './w:r[not(preceding-sibling::w:r//w:t)][not(w:rPr/w:sz[@w:val=\\\"16\\\"])][../w:pPr[w:pStyle[@w:val=\\\"Heading1\\\"]]/w:rPr]/w:t[1]'\n",
    "mainstation_xpath4 = './w:r[not(preceding-sibling::w:r//w:t)][not(w:rPr/w:sz[@w:val=\\\"16\\\"])][../w:pPr[w:pStyle[@w:val=\\\"Heading2\\\"]]/w:rPr]/w:t[1]'\n",
    "mainstation_xpath5 = './w:r[not(preceding-sibling::w:r//w:t)][not(w:rPr/w:sz[@w:val=\\\"16\\\"])][../w:pPr[w:pStyle[@w:val=\\\"Heading3\\\"]]/w:rPr]/w:t[1]'\n",
    "mainstation_xpath6 = './w:r[not(preceding-sibling::w:r//w:t)][not(w:rPr/w:sz[@w:val=\\\"16\\\"])][../w:pPr[w:pStyle[@w:val=\\\"Heading4\\\"]]/w:rPr]/w:t[1]'\n",
    "first_token_para_xpath = './w:r[//w:t]/w:t[1]'\n",
    "\n",
    "stations = pd.DataFrame(columns=['station','type','description'])\n",
    "        \n",
    "def is_mainst(para, mainstation, initial_letter, counter):\n",
    "    paraxp = para.xpath(first_token_para_xpath, namespaces=ns)\n",
    "    mainxpath = \"\"\n",
    "    if paraxp:\n",
    "        \n",
    "        # If text is capitalized (with exception for stations starting with \"Mc\")L\n",
    "        if paraxp[0].text.isupper() or paraxp[0].text.startswith(\"Mc\") and paraxp[0].text[2:].isupper():\n",
    "            \n",
    "            # See if xpath matches a mainstation xpath:\n",
    "            mainxpath = para.xpath(mainstation_xpath, namespaces=ns)\n",
    "            if not mainxpath:\n",
    "                mainxpath = para.xpath(mainstation_xpath2, namespaces=ns)\n",
    "            if not mainxpath:\n",
    "                mainxpath = para.xpath(mainstation_xpath3, namespaces=ns)\n",
    "            if not mainxpath:\n",
    "                mainxpath = para.xpath(mainstation_xpath4, namespaces=ns)\n",
    "            if not mainxpath:\n",
    "                mainxpath = para.xpath(mainstation_xpath5, namespaces=ns)\n",
    "            if not mainxpath:\n",
    "                mainxpath = para.xpath(mainstation_xpath6, namespaces=ns)\n",
    "                \n",
    "            # Filter out station names of length 1, station names that start with initial\n",
    "            # of previous main station (e.g. \"Y BOOTHAM JUNCTION\") or that start with an\n",
    "            # open square bracket or parenthesis:\n",
    "            if mainxpath and len(mainxpath[0].text.strip()) > 1 and not mainxpath[0].text.startswith(initial_letter + \" \") and not mainxpath[0].text.startswith(\"[\") and not mainxpath[0].text.startswith(\"(\"):\n",
    "                counter += 1\n",
    "                mainstation = mainxpath[0].text\n",
    "                initial_letter = mainstation[0]\n",
    "                return mainstation, initial_letter, counter\n",
    "            else:\n",
    "                return mainstation, initial_letter, counter\n",
    "        else:\n",
    "            return mainstation, initial_letter, counter\n",
    "    else:\n",
    "        return mainstation, initial_letter, counter\n",
    "\n",
    "mainstation = \"\"\n",
    "initial_letter = \"\"\n",
    "lowerstation = \"\"\n",
    "dText = dict()\n",
    "counter = 0\n",
    "for i, para in enumerate(et.xpath('//w:p', namespaces=ns)):\n",
    "    text = para.xpath('./w:r/w:t', namespaces=ns)\n",
    "    description = \" \".join([t.text for t in text])\n",
    "    mainstation, initial_letter, counter = is_mainst(para, mainstation, initial_letter, counter)\n",
    "    print(mainstation)\n",
    "    description = description.lstrip('\\x01').strip()\n",
    "    if description:\n",
    "        if (counter, mainstation) in dText:\n",
    "            dText[(counter, mainstation)].append(description)\n",
    "        else:\n",
    "            description = re.sub('^(' + re.escape(mainstation) + ')', '\\1', description).lstrip('\\x01').strip()\n",
    "            description = re.sub(r\" +\", \" \", description).lstrip('\\x01').strip()\n",
    "            if description:\n",
    "                dText[(counter, mainstation)] = [description]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing main stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStations = collections.OrderedDict(dText)\n",
    "\n",
    "indices = []\n",
    "stations = []\n",
    "descriptions = []\n",
    "for k in dStations:\n",
    "    indices.append(k[0])\n",
    "    stations.append(k[1])\n",
    "    descriptions.append(dStations[k])\n",
    "\n",
    "stationdf = pd.DataFrame(columns=[\"Index\", \"Station\", \"Description\"])\n",
    "stationdf[\"Index\"] = indices\n",
    "stationdf[\"Station\"] = stations\n",
    "stationdf[\"Description\"] = descriptions\n",
    "stationdf = stationdf.set_index(\"Index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regex to find substations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Quicks intro:\n",
    "companies = {\"AN Jt\":\"Ashby & Nuneaton Joint.\",\n",
    "    \"ANSW\":\"Alexandra (Newport & South Wales) Docks & Railway.\",\n",
    "    \"Ax Jt\":\"Axholme Joint.\",\n",
    "    \"Bak\":\"Bakerloo Line.\",\n",
    "    \"BC\":\"Bishops Castle.\",\n",
    "    \"BE\":\"Bristol & Exeter.\",\n",
    "    \"BG\":\"Birmingham & Gloucester.\",\n",
    "    \"BLCJ\":\"Birkenhead, Lancashire & Cheshire Junction.\",\n",
    "    \"BM\":\"Brecon & Merthyr.\",\n",
    "    \"BPGV\":\"Burry Port & Gwendraeth Valley.\",\n",
    "    \"BR\":\"British Railways (whilst nationalised).\",\n",
    "    \"BT\":\"Blyth & Tyne.\",\n",
    "    \"BWA\":\"Bideford, Westward Ho! & Appledore. \",\n",
    "    \"Cal\":\"Caledonian.\",\n",
    "    \"Cam\":\"Cambrian.\",\n",
    "    \"Camp\":\"Campbeltown & Machrihanish Light.\",\n",
    "    \"CE\":\"Clifton Extension Joint.\",\n",
    "    \"Cen\":\"Central Line.\",\n",
    "    \"CGU\":\"City of Glasgow Union.\",\n",
    "    \"CHP\":\"Cromford & High Peak.\",\n",
    "    \"CKP\":\"Cockermouth, Keswick & Penrith.\",\n",
    "    \"CLC\":\"Cheshire Lines Committee. \",\n",
    "    \"CMDP\":\"Cleobury Mortimer & Ditton Priors Light.\",\n",
    "    \"CO Jt\":\"Croydon & Oxted Joint.\",\n",
    "    \"Croydon\":\"Croydon Tramlink.\",\n",
    "    \"CVH\":\"Colne Valley & Halstead.\",\n",
    "    \"CW Jc\":\"Cleator & Workington Junction.\",\n",
    "    \"DA\":\"Dundee & Arbroath (original and later Joint).\",\n",
    "    \"DB Jt\":\"Dumbarton & Balloch Joint.\",\n",
    "    \"Dist\":\"District Line (strictly Metropolitan District).\",\n",
    "    \"Dock\":\"Docklands Light.\",\n",
    "    \"DPA\":\"Dundee & Perth & Aberdeen Junction.\",\n",
    "    \"EA\":\"East Anglian.\",\n",
    "    \"EC\":\"Eastern Counties.\",\n",
    "    \"Ed & Dalk\":\"Edinburgh & Dalkeith.\",\n",
    "    \"EG\":\"Edinburgh & Glasgow.\",\n",
    "    \"EK\":\"East Kent Light.\",\n",
    "    \"EU\":\"Eastern Union.\",\n",
    "    \"EWYU\":\"East & West Yorkshire Union.\",\n",
    "    \"Fur\":\"Furness.\",\n",
    "    \"FYN\":\"Freshwater, Yarmouth & Newport.\",\n",
    "    \"GBK Jt\":\"Glasgow, Barrhead & Kilmarnock Joint.\",\n",
    "    \"GC\":\"Great Central.\",\n",
    "    \"GC GI\":\"Great Central (Grimsby & Immingham electric tramway).\",\n",
    "    \"GE\":\"Great Eastern.\",\n",
    "    \"GJ\":\"Grand Junction. \",\n",
    "    \"Glyn\":\"Glyn Valley Tramway. \",\n",
    "    \"GN\":\"Great Northern.\",\n",
    "    \"GNS\":\"Great North of Scotland.\",\n",
    "    \"GP Jt\":\"Glasgow & Paisley Joint.\",\n",
    "    \"GSW\":\"Glasgow & South Western.\",\n",
    "    \"GU\":\"Glasgow Underground.\",\n",
    "    \"GW\":\"Great Western. \",\n",
    "    \"HB\":\"Hull & Barnsley.\",\n",
    "    \"HC\":\"Hammersmith & City Joint.\",\n",
    "    \"High\":\"Highland.\",\n",
    "    \"IoW\":\"Isle of Wight.\",\n",
    "    \"IWC\":\"Isle of Wight Central.\",\n",
    "    \"Jub\":\"Jubilee Line.\",\n",
    "    \"KB\":\"Kilsyth & Bonnybridge Joint.\",\n",
    "    \"KE\":\"Knot(t) End.\",\n",
    "    \"KES\":\"Kent & East Sussex Light.\",\n",
    "    \"L&B\":\"London & Birmingham.\",\n",
    "    \"LBSC\":\"London, Brighton & South Coast.\",\n",
    "    \"LCD\":\"London Chatham & Dover. \",\n",
    "    \"LM\":\"Liverpool & Manchester.\",\n",
    "    \"LMS\":\"London, Midland & Scottish.\",\n",
    "    \"LNE\":\"London & North Eastern.\",\n",
    "    \"LNW\":\"London & North Western.\",\n",
    "    \"LO\":\"Liverpool Overhead.\",\n",
    "    \"LPJ\":\"Lancaster & Preston Junction.\",\n",
    "    \"LPTB\":\"London Passenger Transport Board.\",\n",
    "    \"LSW\":\"London & South Western.\",\n",
    "    \"LTS\":\"London, Tilbury & Southend.\",\n",
    "    \"LU\":\"Lancashire Union.\",\n",
    "    \"LY\":\"Lancashire & Yorkshire.\",\n",
    "    \"Lynton \":\"Lynton & Barnstaple. \",\n",
    "    \"Manch\":\"Manchester Metrolink.\",\n",
    "    \"MC\":\"Maryport & Carlisle.\",\n",
    "    \"Met\":\"Metropolitan Railway/ Line\",\n",
    "    \"Met GNC\":\"Metropolitan (Great Northern & City Section).\",\n",
    "    \"MGN\":\"Midland and Great Northern Joint line. \",\n",
    "    \"Mid\":\"Midland.\",\n",
    "    \"MK\":\"Monkland & Kirkintilloch.\",\n",
    "    \"MS&L\":\"Manchester, Sheffield & Lincolnshire.\",\n",
    "    \"MSJA\":\"Manchester, South Junction & Altrincham.\",\n",
    "    \"MSWJ\":\"Midland & South Western Junction.\",\n",
    "    \"N&B\":\"Neath & Brecon.\",\n",
    "    \"NB\":\"North British.\",\n",
    "    \"NC\":\"Newcastle & Carlisle.\",\n",
    "    \"NE\":\"North Eastern.\",\n",
    "    \"Newtyle\":\"Dundee & Newtyle.\",\n",
    "    \"Nidd\":\"Nidd Valley Light.\",\n",
    "    \"NL\":\"North London.\",\n",
    "    \"Nor\":\"Northern Line.\",\n",
    "    \"Norfolk & S\":\"Norfolk & Suffolk Joint.\",\n",
    "    \"NS\":\"North Staffordshire.\",\n",
    "    \"NSWJ\":\"North & South Western Junction Joint.\",\n",
    "    \"NU\":\"North Union/North Union Joint.\",\n",
    "    \"NWNG\":\"North Wales Narrow Gauge.\",\n",
    "    \"OAGB\":\"Oldham, Ashton & Guide Bridge Junction Joint. \",\n",
    "    \"PDSW\":\"Plymouth, Devonport & South Western Junction.\",\n",
    "    \"Picc\":\"Piccadilly Line.\",\n",
    "    \"PLA\":\"Port of London Authority.\",\n",
    "    \"PPW Jt\":\"Portpatrick & Wigtownshire Joint.\",\n",
    "    \"PT\":\"Port Talbot Railway & Docks.\",\n",
    "    \"PW\":\"Preston & Wyre (original and later Joint).\",\n",
    "    \"Raven\":\"Ravenglass & Eskdale.\",\n",
    "    \"RHD\":\"Romney, Hythe & Dymchurch. \",\n",
    "    \"Rhy\":\"Rhymney.\",\n",
    "    \"RSB\":\"Rhondda & Swansea Bay.\",\n",
    "    \"Rye & C\":\"Rye & Camber Tramway.\",\n",
    "    \"S&D\":\"Stockton & Darlington.\",\n",
    "    \"Scot Cent\":\"Scottish Central.\",\n",
    "    \"SD Jt\":\"Somerset & Dorset Joint.\",\n",
    "    \"SE\":\"South Eastern.\",\n",
    "    \"SEC\":\"South Eastern & Chatham.\",\n",
    "    \"SH Jt\":\"Shrewsbury & Hereford Joint.\",\n",
    "    \"SIT\":\"Swansea Improvements & Tramways Company (Swansea & Mumbles).\",\n",
    "    \"SK\":\"Swinton & Knottingley Joint.\",\n",
    "    \"SM\":\"Shropshire & Montgomeryshire Light.\",\n",
    "    \"SMJ\":\"Stratford-upon-Avon & Midland Junction. \",\n",
    "    \"SR\":\"Southern.\",\n",
    "    \"SSMWC\":\"South Shields, Marsden & Whitburn Colliery.\",\n",
    "    \"SW Jt\":\"Severn & Wye Joint.\",\n",
    "    \"SY\":\"South Yorkshire (later part of GC).\",\n",
    "    \"TFG Jt\":\"Tottenham & Forest Gate Joint. \",\n",
    "    \"TH Jt\":\"Tottenham & Hampstead Joint.\",\n",
    "    \"TV\":\"Taff Vale.\",\n",
    "    \"TWM\":\"Tyne & Wear Metro.\",\n",
    "    \"Vic\":\"Victoria Line.\",\n",
    "    \"VoR\":\"Vale of Rheidol.\",\n",
    "    \"W Lancs\":\"West Lancashire.\",\n",
    "    \"WCE Jt\":\"Whitehaven, Cleator & Egremont Joint.\",\n",
    "    \"WCP\":\"Weston, Clevedon & Portishead Light.\",\n",
    "    \"WELCP\":\"West End of London & Crystal Palace.\",\n",
    "    \"WH\":\"Welsh Highland.\",\n",
    "    \"WL\":\"West London Joint (including Extension). \",\n",
    "    \"WMC\":\"Wilsontown, Morningside & Coltness.\",\n",
    "    \"WMCQ \":\"Wrexham, Mold & Connahâ€™s Quay.\",\n",
    "    \"WP Jt\":\"Weymouth & Portland Joint.\",\n",
    "    \"WRG Jt\":\"West Riding & Grimsby Joint.\",\n",
    "    \"WS\":\"West Sussex (Selsey Tramway).\",\n",
    "    \"WSC Jt\":\"Woodside & South Croydon Jt.\",\n",
    "    \"WSM\":\"West Somerset Mineral\"}\n",
    "\n",
    "# From Quicks intro:\n",
    "stntypes = [\"AOT\", \"CLO\", \"CO\", \"CO N\", \"CO TT\", \"ND\", \"NG\", \"NON-TT\", \"OP\", \"P\", \"REOP\", \"TT\", \"HL\", \"LL\", \"HB\", \"HBA\", \"NG\", \"TT\"]\n",
    "\n",
    "# Most common last tokens:\n",
    "keywords = [\"PLATFORM\", \"PLATFORMS\", \"HALT\", \"INTERNATIONAL\", \"JUNCTION\", \"CAMP\", \"CENTRAL\", 'ROAD', \n",
    "            'JUNCTION', 'BRIDGE', 'STREET', 'PARK', 'LANE', 'HILL', 'COLLIERY', 'TOWN', 'GREEN', \n",
    "            'CENTRAL', 'CROSSING', 'NORTH', 'LEVEL', 'EAST', 'DOCK', 'WEST', 'GATE', 'CROSS', 'HALT', \n",
    "            'SOUTH', 'MILL', 'END', 'SIDING', 'HALL', 'HOUSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_decription(mainst, description, substationId):\n",
    "    print(mainst)\n",
    "    \n",
    "    # Original formatting error such as \"DYKEBAR [\", \"Cal]\"\n",
    "    if mainst.endswith(\"[\"):\n",
    "        mainst = mainst[:-1]\n",
    "        description[0] = \"[\" + description[0]\n",
    "    \n",
    "    dSubstations = dict()\n",
    "    \n",
    "    rsubst = r\"[A-Z ?\\-?\\&? ?]+ \"\n",
    "    rsubstInitial = r\"^(\" + mainst[0] + \"[ |\\-]([A-Z ?\\-?\\&? ?]+)+) \"\n",
    "    \n",
    "    substname = \"\"\n",
    "    \n",
    "    for line in description:\n",
    "        match1 = re.match(rsubst, line)\n",
    "        match2 = re.match(rsubstInitial, line)\n",
    "        if match2:\n",
    "            if not match2.group(0).strip() in companies:\n",
    "                substname = match2.group(0).strip()\n",
    "                substationId += 1\n",
    "        elif match1:\n",
    "            if len(match1.group(0).strip()) > 1 and not match1.group(0).strip() in companies:\n",
    "                substname = match1.group(0).strip()\n",
    "                substationId += 1\n",
    "        if substname == \"\":\n",
    "            substname = mainst\n",
    "            substationId += 1\n",
    "        stup = (substationId, substname)\n",
    "        if not stup in dSubstations:\n",
    "            line = re.sub(r\"^\" + substname, \"\", line)\n",
    "            dSubstations[stup] = line.strip()\n",
    "        else:\n",
    "            dSubstations[stup] += \" \" + line.strip()\n",
    "                \n",
    "    return dSubstations, substationId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['MainId', 'MainStation', 'SubId', 'SubStation', 'Description']\n",
    "lst = []\n",
    "subInd = 0\n",
    "for i, row in stationdf.iterrows():\n",
    "    main_station = row[\"Station\"]\n",
    "    description = row[\"Description\"]\n",
    "    dSubstations, subInd = process_decription(main_station, description, subInd)\n",
    "    for ss in dSubstations:\n",
    "        lst.append([i, main_station, ss[0], ss[1], dSubstations[ss]])\n",
    "subsdf = pd.DataFrame(lst, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming abbreviated substations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subst_rename(main, sub):\n",
    "    sub = sub.replace(\"&\", \" AND \")\n",
    "    sub = re.sub(' +', ' ', sub)\n",
    "    rsub = []\n",
    "    translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
    "    main = main.translate(translator).split()\n",
    "    sub = sub.translate(translator).split()\n",
    "    if sub != main:\n",
    "        \n",
    "        # Sometimes, first token is split by whitespace. Join split tokens:\n",
    "        # e.g. ['F', 'ISHPONDS']\n",
    "        if len(sub) == 2:\n",
    "            if sub[0] + sub[1] == main[0]:\n",
    "                sub = [sub[0] + sub[1]]\n",
    "        # e.g. ['L', 'ITTLE', 'ORMESBY']\n",
    "        if len(sub) > 2:\n",
    "            if sub[0] + sub[1] == main[0]:\n",
    "                sub = [sub[0] + sub[1]] + sub[2:]\n",
    "        \n",
    "        # Sometimes, first token is split by whitespace. Join split tokens:\n",
    "        # e.g. 'CROSS KEYS' and 'CROSSKEYS'\n",
    "        if len(main) == 2:\n",
    "            if main[0] + main[1] == sub[0]:\n",
    "                main = [main[0] + main[1]]\n",
    "        # e.g. \n",
    "        if len(main) > 2:\n",
    "            if main[0] + main[1] == sub[0]:\n",
    "                main = [main[0] + main[1]] + main[2:]\n",
    "                \n",
    "        # CASE 1: Main station is just one token, substation is more than one token:\n",
    "        if len(main) == 1 and len(sub) > 1:\n",
    "            \n",
    "            # e.g. 'ALTON' and 'ALTON PARK'\n",
    "            if main[0] == sub[0]:\n",
    "                rsub += sub\n",
    "            \n",
    "            # e.g. 'BONNYRIGG' and 'BONNYRIGGE DEPOT'\n",
    "            elif sub[0].startswith(main[0]):\n",
    "                rsub += sub\n",
    "            \n",
    "            # e.g. 'BIRMINGHAM' and 'B NEW STREET'\n",
    "            elif main[0][0] == sub[0][0] and len(sub[0]) == 1:\n",
    "                rsub.append(main[0])\n",
    "                rsub += sub[1:]\n",
    "            \n",
    "            # e.g. 'BARGEDDIE' and 'BARGE DDI E'\n",
    "            elif \"\".join(sub) == main[0]:\n",
    "                rsub += main\n",
    "                \n",
    "            # e.g. 'ALLOA' and 'SOUTH ALLOA'\n",
    "            elif any(x == main[0] for x in sub):\n",
    "                rsub += sub\n",
    "            \n",
    "            # e.g. 'AIRDRIE' and 'COMMONHEAD A NORTH'\n",
    "            elif any(len(x) == 1 and x[0] == main[0][0] for x in sub):\n",
    "                for x in sub:\n",
    "                    if len(x) == 1 and x[0] == main[0][0]:\n",
    "                        rsub.append(main[0])\n",
    "                    else:\n",
    "                        rsub.append(x)\n",
    "                        \n",
    "            # e.g. 'CAERNARVON' and 'CARNARVON CASTLE'\n",
    "            elif any(SequenceMatcher(None, x, main[0]).ratio() >= 0.8 for x in sub):\n",
    "                rsub = sub\n",
    "                \n",
    "            # e.g. 'SOUTHPORT' and 'STEAMPORT MUSEUM'\n",
    "            else:\n",
    "                rsub.append(main[0])\n",
    "                rsub += sub\n",
    "                \n",
    "        # CASE 2: Substation has length 1, mainstation length > 1\n",
    "        elif len(sub) == 1 and len(main) > 1:\n",
    "            \n",
    "            # e.g. 'CLYDACH ON TAWE' and 'CLYDACH'\n",
    "            if any(SequenceMatcher(None, x, sub[0]).ratio() >= 0.8 for x in main):\n",
    "                rsub = sub\n",
    "                \n",
    "            # e.g. 'HIGHGATE ROAD' and 'HL'\n",
    "            elif sub[0] in keywords or sub[0] in stntypes:\n",
    "                rsub += main\n",
    "                rsub += sub\n",
    "                \n",
    "            # e.g. 'BLAENAU FFESTINIOG' and 'DINAS'\n",
    "            else:\n",
    "                rsub = sub\n",
    "                \n",
    "        # CASE 3: Substation has length 1, mainstation length 1\n",
    "        elif len(sub) == 1 and len(main) == 1:\n",
    "            \n",
    "            # e.g. 'BELMONT' and 'JUNCTION'\n",
    "            if sub[0] in keywords or sub[0] in stntypes:\n",
    "                rsub += main\n",
    "                rsub += sub\n",
    "            \n",
    "            # e.g. 'SELHURST' and 'SELHUST'\n",
    "            elif SequenceMatcher(None, sub[0], main[0]).ratio() >= 0.8:\n",
    "                rsub += main\n",
    "            \n",
    "            # e.g. 'WALKER' and 'WALKERGATE'\n",
    "            elif sub[0].startswith(main[0]):\n",
    "                rsub += sub\n",
    "                \n",
    "            # e.g. 'TILBURY' and 'BERTHS'\n",
    "            else:\n",
    "                rsub += main\n",
    "                rsub += sub\n",
    "        \n",
    "        # CASE 4: otherwise\n",
    "        # e.g. 'FINCHLEY ROAD' and 'F R AND FROGNAL'\n",
    "        # e.g. 'B ON S AND QUORN' and 'BARROW ON SOAR AND QUORN'\n",
    "        else:\n",
    "            tempmain = []\n",
    "            remsub = []\n",
    "            tsub = []\n",
    "            for x in sub:\n",
    "                if len(x) == 1:\n",
    "                    for m in main:\n",
    "                        if m.startswith(x) and not m in tsub and not m in remsub:\n",
    "                            tsub.append(m)\n",
    "                            remsub.append(x)\n",
    "                    else:\n",
    "                        tsub.append(x)\n",
    "                else:\n",
    "                    tsub.append(x)\n",
    "                    \n",
    "            rsub = [x for x in tsub if not x in remsub]\n",
    "            \n",
    "            # e.g. \"ST A\" or \"S C\" as substation names:\n",
    "            if len(max(rsub, key=len)) <= 2:\n",
    "                rsub = main\n",
    "                \n",
    "        rsub = \" \".join(rsub)\n",
    "        if re.search(r\"\\bLL\\b\", rsub):\n",
    "            rsub = re.sub(r\"\\bLL\\b\", \"LOW LEVEL\", rsub)\n",
    "        if re.search(r\"\\bHL\\b\", rsub):\n",
    "            rsub = re.sub(r\"\\bHL\\b\", \"HIGH LEVEL\", rsub)\n",
    "            \n",
    "        return rsub\n",
    "    else:\n",
    "        return \" \".join(sub)\n",
    "        \n",
    "subsdf['SubStFormatted'] = subsdf.apply(lambda row: subst_rename(row[\"MainStation\"], row[\"SubStation\"]), axis = 1)\n",
    "subsdf = subsdf[[\"MainId\", \"SubId\", \"MainStation\", \"SubStation\", \"SubStFormatted\", \"Description\"]]\n",
    "subsdf.to_pickle('quicks_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_candranker(gazname, unique_placenames_array):\n",
    "    \"\"\"\n",
    "    This function returns the unique alternate names in a given gazetteer\n",
    "    in the format required by DeezyMatch candidate ranker.\"\"\"\n",
    "    with open(gazname + \".txt\", \"w\") as fw:\n",
    "        for pl in unique_placenames_array:\n",
    "            pl = pl.strip()\n",
    "            if pl:\n",
    "                pl = pl.replace('\"', \"\")\n",
    "                fw.write(pl.strip() + \"\\t0\\tfalse\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_placenames_array = list(set(list(np.array(subsdf[\"MainStation\"]))))\n",
    "format_for_candranker(\"../toponym_matching/toponyms/quicks_mainst_queries\", unique_placenames_array)\n",
    "\n",
    "unique_placenames_array = list(set(list(np.array(subsdf[\"SubStFormatted\"]))))\n",
    "format_for_candranker(\"../toponym_matching/toponyms/quicks_subst_queries\", unique_placenames_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37deezy)",
   "language": "python",
   "name": "py37deezy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
