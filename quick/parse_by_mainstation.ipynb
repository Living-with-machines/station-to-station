{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import re\n",
    "import json\n",
    "import dateparser\n",
    "import collections\n",
    "from lxml import etree\n",
    "from xml.etree.ElementTree import XML\n",
    "from random import shuffle\n",
    "docxFileName = \"quick_section4.docx\"\n",
    "docxZip = zipfile.ZipFile(docxFileName)\n",
    "documentXML = docxZip.read('word/document.xml')\n",
    "et = etree.XML(documentXML)\n",
    "ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ABERBEEG\n",
      "ADAM STREET \n",
      "AINSWORTH ROAD \n",
      "ALDWYCH\n",
      "ALEXANDRA PARADE\n",
      "ALFRETON\n",
      "ANNITSFORD\n",
      "ANSTRUTHER\n",
      "ASHURST\n",
      "AYOT\n",
      "BACHAN\n",
      "BACHE\n",
      "BACK OF LAW \n",
      "BAGILLT\n",
      "BARNES\n",
      "BARRS COURT JUNCTION\n",
      "BEDLINGTON\n",
      "BETCHWORTH\n",
      "BETLEY ROAD\n",
      "BIDFORD-ON-AVON\n",
      "BIGLIS/B JUNCTION\n",
      "BODDAM\n",
      "BOâ€™NESS\n",
      "BONNINGTON\n",
      "BOTTOM OF SUTTON INCLINE\n",
      "BOWES BRIDGE\n",
      "BRAMSHOT\n",
      "BRIDLINGTON\n",
      "BRITISH STEEL\n",
      "BRYNDERWEN\n",
      "BRYNGLAS\n",
      "BURNT FEN\n",
      "BUSHEY PARK \n",
      "CAERLEON\n",
      "CAMBRIDGE HEATH\n",
      "CAMPBELTOWN\n",
      "CAMPERDOWN\n",
      "CANLEY\n",
      "CANNON STREET ROAD\n",
      "CANTLEY\n",
      "CAPEL BANGOR\n",
      "CARDIFF\n",
      "CARDIGAN\n",
      "CARLISLE\n",
      "CARLTON MAIN COLLIERY\n",
      "CARLTON/CARLTON IRONWORKS\n",
      "CARLUKE\n",
      "CARMARTHEN\n",
      "CARNO\n",
      "CARSHALTON\n",
      "CARSTAIRS\n",
      "CASTLE DONINGTON & SHARDLOW\n",
      "CASTLE DOUGLAS\n",
      "CASTLE EDEN\n",
      "CASTLEMILK\n",
      "CASTLETHORPE\n",
      "CATHCART\n",
      "CEFN COED\n",
      "CELYNEN\n",
      "CENTRAL\n",
      "CHALK FARM\n",
      "CHALKWELL\n",
      "CHAPELTON\n",
      "CHAPELTOWN\n",
      "CHARFIELD\n",
      "CHARING CROSS\n",
      "CHATHAM\n",
      "CHATHILL\n",
      "CHEADLE\n",
      "CHELLASTON & SWARKESTONE\n",
      "CHEQUERBENT\n",
      "CHERRY BURTON\n",
      "CHESSINGTON\n",
      "CHESTER ROAD\n",
      "CHESTER-LE-STREET\n",
      "CHISELDON\n",
      "CHISLEHURST\n",
      "CHISLET \n",
      "CHITTENING\n",
      "CHORLEYWOOD\n",
      "CHURCH FENTON \n",
      "CHURCH MANOR WAY\n",
      "CHURCH STRETTON\n",
      "CHURCHTOWN\n",
      "CILFREW\n",
      "CINDERFORD\n",
      "CITY AIRPORT\n",
      "CITY ROAD\n",
      "CLACKMANNAN\n",
      "CLACTON-ON-SEA\n",
      "CLAPHAM\n",
      "CLARENCE YARD\n",
      "CLARKSTON\n",
      "CLAYDON\n",
      "CLELAND\n",
      "CLENCHWARTON\n",
      "CLEVELAND PORT\n",
      "CLIBURN\n",
      "CLIDDESDEN\n",
      "CLIFTON\n",
      "CLIFTON\n",
      "CLIFTON MILL\n",
      "CLOVENFORDS\n",
      "CLOWNE\n",
      "CLOY\n",
      "CLYNE\n",
      "COANWOOD\n",
      "COATDYKE\n",
      "COCKERMOUTH\n",
      "COGAN\n",
      "COLEBY BRIDGE\n",
      "COLEFORD JUNCTION\n",
      "COLEHAM EXCURSION\n",
      "COLEHOUSE LANE\n",
      "COLESHILL\n",
      "COLLIERY WORKS PLATFORM\n",
      "COLLINGBOURNE\n",
      "COLLYWELL BAY\n",
      "COLNBROOK\n",
      "COLWYN\n",
      "COLYFORD\n",
      "COLYTON\n",
      "COLZIUM\n",
      "CONSTABLE BURTON\n",
      "COP END\n",
      "COPPERHOUSE\n",
      "COPPLESTONE\n",
      "CORYATES\n",
      "COULTER\n",
      "COWDENBEATH\n",
      "COWES\n",
      "COXHOE\n",
      "COXLODGE\n",
      "CRAIGENDORAN\n",
      "CRESWELL\n",
      "CRICCIETH\n",
      "CRIMSTONE\n",
      "CROESOR JUNCTION\n",
      "CROFT\n",
      "CRUMLIN BURROWS\n",
      "DACRE\n",
      "DEE STREET\n",
      "DELABOLE\n",
      "DINTING\n",
      "DIXON FOLD \n",
      "DONIBRISTLE\n",
      "DONIFORD\n",
      "DONINGTON ROAD\n",
      "DORE & TOTLEY \n",
      "DUDLEY COLLIERY\n",
      "DULLATUR\n",
      "DULLINGHAM\n",
      "DUNDEE\n",
      "DUNGENESS\n",
      "DUNHAM\n",
      "DUNKERTON\n",
      "DUNLOP\n",
      "DUNNINGTON\n",
      "DUNVANT\n",
      "DURLEY\n",
      "DURNSFORD ROAD\n",
      "EARBY\n",
      "EARLSFIELD\n",
      "EAST DIDSBURY\n",
      "EAST HALTON\n",
      "EASTRY\n",
      "EASTWOOD\n",
      "EBBW JUNCTION \n",
      "EBCHESTER\n",
      "ECCLESHILL\n",
      "EDENHAM\n",
      "EDINGTON & BRATTON\n",
      "EGGINTON\n",
      "EGHAM\n",
      "EGLINTON PARK\n",
      "EGLINTON STREET\n",
      "EGLOSKERRY\n",
      "ELFORD\n",
      "ELGIN\n",
      "ELHAM\n",
      "ELLERBY\n",
      "ELLERDINE\n",
      "ELLIOT JUNCTION\n",
      "ELY\n",
      "EMBLETON\n",
      "ENERGLYN & CHURCHILL PARK\n",
      "ENTHORPE\n",
      "ENZIE\n",
      "ESGAIRGEILIOG\n",
      "ESTON\n",
      "EVANTON\n",
      "EVERCREECH\n",
      "EVERSHOT\n",
      "EWELL\n",
      "EXETER\n",
      "FAIRLIE\n",
      "FALKIRK\n",
      "FELIXSTOWE\n",
      "FENTON\n",
      "FERRYHILL\n",
      "FILLEIGH\n",
      "FILTON\n",
      "FINNINGLEY \n",
      "FISHPOND\n",
      "FISHPONDS\n",
      "FOCHRIW\n",
      "FOLKESTONE\n",
      "FORYD\n",
      "GADLYS ROAD\n",
      "GAERWEN\n",
      "GALLOWSHALL\n",
      "GAMMER LANE\n",
      "GILESTON\n",
      "GILGARRAN\n",
      "GILLESPIE ROAD\n",
      "GISBURN\n",
      "GORSE LANE\n",
      "GOVILON\n",
      "GOXHILL\n",
      "GRAINSBY\n",
      "GRANVILLE STREET\n",
      "GREEN BANK\n",
      "GREEN ROAD\n",
      "HALFWAY\n",
      "HALLILOO\n",
      "HALLING\n",
      "HAMILTON SQUARE\n",
      "HARPUR HILL\n",
      "HARRIETSHAM\n",
      "HENDRE QUARRY\n",
      "HENDREFORGAN\n",
      "HENIARTH\n",
      "HENLEY-ON-THAMES\n",
      "HOLYWELL\n",
      "HORNCHURCH\n",
      "HORNSEY ROAD\n",
      "(H) NEWINGTON\n",
      "ICKENHAM\n",
      "ILMER\n",
      "IMPERIAL COTTAGES\n",
      "JACKAMENTS BRIDGE\n",
      "JACKFIELD\n",
      "KEADBY\n",
      "KELVIN BRIDGE\n",
      "KEMPSTON & ELSTOW\n",
      "KETTERING\n",
      "KILBRIDE\n",
      "KILCONQUHAR\n",
      "KILLIECRANKIE\n",
      "KILMARONOCK\n",
      "KILSBY & CRICK\n",
      "KIMBERLEY PARK\n",
      "KINGS HEATH\n",
      "KINGSCOTE\n",
      "KINGSKERSWELL\n",
      "KINGSTON CROSSING\n",
      "KIRKBY-IN-FURNESS\n",
      "LATHOL\n",
      "LAYTON HAWES FARM\n",
      "LEDSTON\n",
      "LEEGATE\n",
      "LEEMING BAR\n",
      "LEIGH\n",
      "LILBOURNE\n",
      "LINEFOOT\n",
      "LLANDRE\n",
      "LLANDYBIE\n",
      "LLANDYSSUL\n",
      "LLANFYLLIN\n",
      "LLANIDLOES\n",
      "LLANSANTFFRAID\n",
      "LLANTWIT FARDRE\n",
      "LONDESBOROUGH PARK\n",
      "LONDESBOROUGH ROAD\n",
      "LONDON CITY AIRPORT \n",
      "LYDHAM HEATH\n",
      "LYDIATE\n",
      "LYDSTEP\n",
      "MACMERRY\n",
      "MAENCLOCHOG\n",
      "MAESYCRUGIAU\n",
      "MANCHESTER ROAD\n",
      "MARYPORT\n",
      "MILES PLATTING\n",
      "MILFORD & BROCTON\n",
      "MILLOM\n",
      "MUIRTON\n",
      "NELSON\n",
      "NEW MILL END\n",
      "NEWBURY PARK\n",
      "NOTTINGHAM ROAD \n",
      "NOTTON & ROYSTON\n",
      "OLD SWAN\n",
      "OUTWOOD\n",
      "PANT SALOP\n",
      "PEMBRIDGE\n",
      "PICKBURN & BRODSWORTH\n",
      "PLAS-Y-COURT\n",
      "PORTKNOCKIE\n",
      "PYLLE HILL\n",
      "RADCLIFFE NOTTS\n",
      "RUSHFORD\n",
      "ST PAULS\n",
      "ST PETERS\n",
      "SINGLETON \n",
      "STOKE-ON-TRENT\n",
      "THORNTON ABBEY\n",
      "TOXTETH DOCK\n",
      "UPHILL\n",
      "USK\n",
      "VERNEY JUNCTION\n",
      "WALLINGFEN\n",
      "WALNUT TREE\n",
      "WANLOCKHEAD\n",
      "WHAPLODE\n",
      "WHITLEY\n",
      "WIMBLINGTON\n",
      "WOOD GREEN OLD BESCOT\n",
      "YAPTON\n",
      "YNYSYGEINON\n",
      "YORK ROAD\n"
     ]
    }
   ],
   "source": [
    "mainstation_xpath = './w:r[not(preceding-sibling::w:r//w:t)][not(w:rPr/w:sz[@w:val=\"16\"])][w:rPr/w:b[not(@w:val=\"0\")]]/w:t[1]'\n",
    "mainstation_xpath2 = './w:r[not(preceding-sibling::w:r//w:t)][not(w:rPr/w:sz[@w:val=\"16\"])][../w:pPr[w:pStyle]/w:rPr/w:b[@w:val=\"0\"]]/w:t[1]'\n",
    "\n",
    "first_token_para_xpath = './w:r[//w:t]/w:t[1]'\n",
    "\n",
    "stations = pd.DataFrame(columns=['station','type','description'])\n",
    "\n",
    "def is_upper(para):\n",
    "    if para.xpath(first_token_para_xpath, namespaces=ns):\n",
    "        if para.xpath(first_token_para_xpath, namespaces=ns)[0].text.isupper():\n",
    "            return 'station'\n",
    "        else: \n",
    "            return 'new_line'\n",
    "\n",
    "mainstation = \"\"\n",
    "initial_letter = \"\"\n",
    "lowerstation = \"\"\n",
    "dText = dict()\n",
    "counter = 0\n",
    "for i, para in enumerate(et.xpath('//w:p', namespaces=ns)):\n",
    "    text = para.xpath('./w:r/w:t', namespaces=ns)\n",
    "    description = \" \".join([t.text for t in text])\n",
    "    if is_upper(para) == 'station':\n",
    "        mainxpath = para.xpath(mainstation_xpath2, namespaces=ns)\n",
    "        # Filter out wrongly formatted substations:\n",
    "        if mainxpath and len(mainxpath[0].text) > 1 and not mainxpath[0].text.startswith(initial_letter + \" \"):\n",
    "            print(mainxpath[0].text)\n",
    "            counter += 1\n",
    "            mainstation = mainxpath[0].text\n",
    "            initial_letter = mainstation[0]\n",
    "    description = description.lstrip('\\x01').strip()\n",
    "    if description:\n",
    "        if (counter, mainstation) in dText:\n",
    "            dText[(counter, mainstation)].append(description)# += \"\\n\" + description\n",
    "        else:\n",
    "            description = re.sub('^(' + re.escape(mainstation) + ')', '\\1', description).lstrip('\\x01').strip()\n",
    "            description = re.sub(r\" +\", \" \", description).lstrip('\\x01').strip()\n",
    "            if description:\n",
    "                dText[(counter, mainstation)] = [description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStations = collections.OrderedDict(dText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "stations = []\n",
    "descriptions = []\n",
    "for k in dStations:\n",
    "    indices.append(k[0])\n",
    "    stations.append(k[1])\n",
    "    descriptions.append(dStations[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationdf = pd.DataFrame(columns=[\"Index\", \"Station\", \"Description\"])\n",
    "stationdf[\"Index\"] = indices\n",
    "stationdf[\"Station\"] = stations\n",
    "stationdf[\"Description\"] = descriptions\n",
    "stationdf = stationdf.set_index(\"Index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationdf.to_pickle('quick_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'to_annotate/173.txt'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2ab9e0e0e7e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get 100 random entries:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstationdf_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"to_annotate/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[[[STATION: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Station\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"]]]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Description\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'to_annotate/173.txt'"
     ]
    }
   ],
   "source": [
    "stationdf_sample = stationdf.sample(n=100, random_state=42)\n",
    "\n",
    "# Get 100 random entries:\n",
    "for i, row in stationdf_sample.iterrows():\n",
    "    with open(\"to_annotate/\" + str(i) + \".txt\", \"w\") as fw:\n",
    "        fw.write(\"[[[STATION: \" + row[\"Station\"] + \"]]]\")\n",
    "        for d in row[\"Description\"]:\n",
    "            fw.write(\"\\n\" + d)\n",
    "\n",
    "# Get 25 long entries:\n",
    "stationdf_sample = stationdf.sample(frac=1, random_state=42)\n",
    "counter = 1\n",
    "for i, row in stationdf_sample.iterrows():\n",
    "    if len(row['Description']) >= 10:\n",
    "        with open(\"to_annotate/\" + str(i) + \".txt\", \"w\") as fw:\n",
    "            fw.write(\"[[[STATION: \" + row[\"Station\"] + \"]]]\")\n",
    "            for d in row[\"Description\"]:\n",
    "                fw.write(\"\\n\" + d)\n",
    "        if counter >= 25:\n",
    "            break\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing\n",
    "unpickled_df = pd.read_pickle(\"quick_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Station                                        Description\n",
       "Index                                                             \n",
       "25     ABERAVON  [[RSB] {map 85}., A SEA SIDE   op 1 March 1899..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Station</th>\n      <th>Description</th>\n    </tr>\n    <tr>\n      <th>Index</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25</th>\n      <td>ABERAVON</td>\n      <td>[[RSB] {map 85}., A SEA SIDE   op 1 March 1899...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "## testing\n",
    "unpickled_df.loc[unpickled_df.Station.str.startswith('ABERAVON', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## testing\n",
    "h1 = et.xpath('//./w:r[preceding-sibling::w:pPr/w:pStyle[@w:val=\"Heading1\"]][1]/w:t[1]', namespaces=ns)\n",
    "h2 = et.xpath('//./w:r[preceding-sibling::w:pPr/w:pStyle[@w:val=\"Heading2\"]][1]/w:t[1]', namespaces=ns)\n",
    "h3 = et.xpath('//./w:r[preceding-sibling::w:pPr/w:pStyle[@w:val=\"Heading3\"]][1]/w:t[1]', namespaces=ns)\n",
    "h4 = et.xpath('//./w:r[preceding-sibling::w:pPr/w:pStyle[@w:val=\"Heading4\"]][1]/w:t[1]', namespaces=ns)\n",
    "main1 = et.xpath('//.'+mainstation_xpath, namespaces=ns)\n",
    "main2 = et.xpath('//.'+mainstation_xpath2, namespaces=ns)\n",
    "\n",
    "mains = list(unpickled_df.Station)\n",
    "print('Heading1:\\n')\n",
    "for a in h1:\n",
    "    if a not in mains:\n",
    "        print(a.text)\n",
    "print()\n",
    "print('Heading2:\\n')\n",
    "for a in h2:\n",
    "    if a not in mains:\n",
    "        print(a.text)\n",
    "print()\n",
    "print('Heading3:\\n')\n",
    "for a in h3:\n",
    "    if a not in mains:\n",
    "        print(a.text)\n",
    "print()\n",
    "print('Heading4:\\n')\n",
    "for a in h4:\n",
    "    if a not in mains:\n",
    "        print(a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "main1 = et.xpath(mainstation_xpath, namespaces=ns)\n",
    "main2 = et.xpath(mainstation_xpath2, namespaces=ns)\n",
    "\n",
    "main1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}