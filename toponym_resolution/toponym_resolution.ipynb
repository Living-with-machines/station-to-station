{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py37deezy/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tools import eval_methods, resolution_methods\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import random\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gazetteer_df = pd.read_csv(\"../processed/wikidata/british_isles_gazetteer.csv\", header=0, index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/resources/wikipedia/extractedResources/overall_entity_freq.pickle\", 'rb') as fp:\n",
    "    wikipedia_entity_overall_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deezy_match test 5 done!\n",
      "deezy_match dev 5 done!\n",
      "deezy_match test 3 done!\n",
      "deezy_match dev 3 done!\n",
      "deezy_match test 1 done!\n",
      "deezy_match dev 1 done!\n"
     ]
    }
   ],
   "source": [
    "# ------------------\n",
    "# Feature selection for dev and test\n",
    "num_candidates_list = [5, 3, 1]\n",
    "settings = [\"test\", \"dev\"]\n",
    "candrank_approaches = [\"deezy_match\"]\n",
    "for num_candidates in num_candidates_list:\n",
    "    for setting in settings:\n",
    "        for candrank in candrank_approaches:\n",
    "            features_file = \"../processed/resolution/features_\" + candrank + \"_\" + setting + str(num_candidates) + \".tsv\"\n",
    "            if not Path(features_file).is_file():\n",
    "                df = pd.read_pickle(\"../processed/resolution/candranking_\" + candrank + \"_\" + setting + str(num_candidates) + \".pkl\")\n",
    "                exp_df = resolution_methods.feature_selection(candrank, df, gazetteer_df, wikipedia_entity_overall_dict)\n",
    "                exp_df.drop_duplicates(subset=['Query','Candidate'], inplace=True)\n",
    "                exp_df.to_csv(features_file, sep=\"\\t\")\n",
    "            print(candrank + \" \" + setting + \" \" + str(num_candidates) + \" done!\")\n",
    "\n",
    "features_dev = pd.read_csv(\"../processed/resolution/features_\" + candrank + \"_dev\" + str(num_candidates) + \".tsv\",sep='\\t', index_col=0)\n",
    "features_test = pd.read_csv(\"../processed/resolution/features_\" + candrank + \"_test\" + str(num_candidates) + \".tsv\",sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_candidates = 1\n",
    "candrank_method = \"deezy_match\"\n",
    "\n",
    "features_dev = pd.read_csv(\"../processed/resolution/features_\" + candrank + \"_dev\" + str(num_candidates) + \".tsv\",sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method and baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will store the results of all methods/baselines as columns in the original structured dataframe:\n",
    "results_test_df = pd.read_pickle(\"../processed/quicks/quicks_test.pkl\")\n",
    "features_test = pd.read_csv(\"../processed/resolution/features_\" + candrank + \"_test\" + str(num_candidates) + \".tsv\",sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries in train and test: 105 105\n",
      "Instances in train and test: 746 4476\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "Classification report on the test split of the dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4373\n",
      "           1       0.86      0.69      0.76       103\n",
      "\n",
      "    accuracy                           0.99      4476\n",
      "   macro avg       0.92      0.84      0.88      4476\n",
      "weighted avg       0.99      0.99      0.99      4476\n",
      "\n",
      "[[ 1.42426317e+00 -5.70736045e-01  9.66669200e-05  2.33409328e-02\n",
      "  -4.06976539e-01  3.63993217e-01  8.16300491e-01  1.56249737e-04\n",
      "   1.39545877e-02]]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Apply our classification method (column \"our_method_all\")\n",
    "# -------------------------------\n",
    "\n",
    "# ------------------------------\n",
    "# Train the classifier with all the features\n",
    "dev_df = features_dev # development set feature vectors\n",
    "use_cols_all = ['f_0','f_1','f_2','f_3','f_4','f_5','f_6','f_7','f_8'] # features to use\n",
    "clf_all = resolution_methods.train_classifier(dev_df, use_cols_all)\n",
    "\n",
    "# ------------------------------\n",
    "# Apply the classifier with all the features\n",
    "features_test_df = features_test # test set feature vectors\n",
    "results_test_df = resolution_methods.our_method_simple(features_test_df, clf_all, use_cols_all, gazetteer_df, results_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Baseline: Apply candrank-most-confident baseline\n",
    "# -------------------------------\n",
    "results_test_df = resolution_methods.candrank_most_confident(features_test_df, results_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Baseline: Apply wikipedia-most-relevant baseline\n",
    "# -------------------------------\n",
    "results_test_df = resolution_methods.wikipedia_most_relevant(features_test_df, results_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Baseline: Apply semantically_most_similar baseline\n",
    "# -------------------------------\n",
    "results_test_df = resolution_methods.semantically_most_similar(features_test_df, results_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1 on training data: 0.681 P@1 on test data: 0.6869\n",
      "feature used: 1 2 3 4 5 6 7 8 9\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# RankLib: Apply learning to rank\n",
    "# -------------------------------\n",
    "\n",
    "code_folder = str(Path(\"../../\").resolve()) + \"/\"\n",
    "filter=\"all\"\n",
    "feature_combination = \"allfeatures\" # Uncomment if you want to use all features \n",
    "cross_val = False\n",
    "\n",
    "# Apply all features combination to test set:\n",
    "results_test_df = resolution_methods.ranklib(features_dev,features_test_df,filter,code_folder,cross_val,results_test_df,feature_combination,num_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MainId</th>\n",
       "      <th>SubId</th>\n",
       "      <th>MainStation</th>\n",
       "      <th>SubStation</th>\n",
       "      <th>SubStFormatted</th>\n",
       "      <th>Description</th>\n",
       "      <th>Final Wikidata ID</th>\n",
       "      <th>Disambiguator</th>\n",
       "      <th>Companies</th>\n",
       "      <th>FirstCompanyWkdt</th>\n",
       "      <th>...</th>\n",
       "      <th>Altnames</th>\n",
       "      <th>Referenced</th>\n",
       "      <th>FirstOpening</th>\n",
       "      <th>LastClosing</th>\n",
       "      <th>Interrupted</th>\n",
       "      <th>our_method_all</th>\n",
       "      <th>candrank_most_confident</th>\n",
       "      <th>wikipedia_most_relevant</th>\n",
       "      <th>semantically_most_similar</th>\n",
       "      <th>ranklib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4212</td>\n",
       "      <td>5467</td>\n",
       "      <td>HEREFORD</td>\n",
       "      <td>H BARTON</td>\n",
       "      <td>HEREFORD BARTON</td>\n",
       "      <td>[GW] op 2 January 1854  (T 29 December) ; clo ...</td>\n",
       "      <td>Q29379045</td>\n",
       "      <td>[]</td>\n",
       "      <td>[GW]</td>\n",
       "      <td>Q843251</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2 January 1854</td>\n",
       "      <td>2 January 1893</td>\n",
       "      <td>False</td>\n",
       "      <td>Q29379045</td>\n",
       "      <td>Q29379045</td>\n",
       "      <td>Q23129</td>\n",
       "      <td>Q29379045</td>\n",
       "      <td>Q29379045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2075</td>\n",
       "      <td>2743</td>\n",
       "      <td>COED ELY</td>\n",
       "      <td>COED ELY</td>\n",
       "      <td>COED ELY</td>\n",
       "      <td>[GW] op 13 July 1925 (Cardiff Divisional Repor...</td>\n",
       "      <td>Q5140512</td>\n",
       "      <td>[]</td>\n",
       "      <td>[GW]</td>\n",
       "      <td>Q843251</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>13 July 1925</td>\n",
       "      <td>9 June 1958</td>\n",
       "      <td>False</td>\n",
       "      <td>Q5140512</td>\n",
       "      <td>Q5140512</td>\n",
       "      <td>Q5140496</td>\n",
       "      <td>Q5140496</td>\n",
       "      <td>Q5140512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6719</td>\n",
       "      <td>8798</td>\n",
       "      <td>PENYFFORDD</td>\n",
       "      <td>PENYFFORDD</td>\n",
       "      <td>PENYFFORDD</td>\n",
       "      <td>[GC] op 1 May 1866 (T 7 th ) ; still open. Ope...</td>\n",
       "      <td>Q3401808</td>\n",
       "      <td>[]</td>\n",
       "      <td>[GC]</td>\n",
       "      <td>Q688684</td>\n",
       "      <td>...</td>\n",
       "      <td>[LEESWOOD, HOPE, HOPE JUNCTION]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1 May 1866</td>\n",
       "      <td>31 December 2001</td>\n",
       "      <td>False</td>\n",
       "      <td>Q3401808</td>\n",
       "      <td>Q3401808</td>\n",
       "      <td>Q2752670</td>\n",
       "      <td>Q28970438</td>\n",
       "      <td>Q3401808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2622</td>\n",
       "      <td>3409</td>\n",
       "      <td>DERBY</td>\n",
       "      <td>DERBY</td>\n",
       "      <td>DERBY</td>\n",
       "      <td>[Birmingham &amp; Derby Junction] temporary op 12 ...</td>\n",
       "      <td>Q3398679</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Birmingham &amp; Derby Junction]</td>\n",
       "      <td>Q3700357</td>\n",
       "      <td>...</td>\n",
       "      <td>[DERBY MIDLAND, DERBY STATION STREET]</td>\n",
       "      <td>[]</td>\n",
       "      <td>11 May 1840</td>\n",
       "      <td>31 December 2001</td>\n",
       "      <td>True</td>\n",
       "      <td>Q3398679</td>\n",
       "      <td>Q3398679</td>\n",
       "      <td>Q43475</td>\n",
       "      <td>Q3398679</td>\n",
       "      <td>Q3398679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4593</td>\n",
       "      <td>5966</td>\n",
       "      <td>INVERUGLAS</td>\n",
       "      <td>INVERUGLAS</td>\n",
       "      <td>INVERUGLAS</td>\n",
       "      <td>[LNE] (non-tt): workmen, Loch Sloy HEP; op 29 ...</td>\n",
       "      <td>Q48807380</td>\n",
       "      <td>[]</td>\n",
       "      <td>[LNE]</td>\n",
       "      <td>Q1092839</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>29 October 1945</td>\n",
       "      <td>1940</td>\n",
       "      <td>False</td>\n",
       "      <td>Q48807380</td>\n",
       "      <td>Q48807380</td>\n",
       "      <td>Q16892730</td>\n",
       "      <td>Q799488</td>\n",
       "      <td>Q48807380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MainId  SubId MainStation  SubStation   SubStFormatted  \\\n",
       "0    4212   5467    HEREFORD    H BARTON  HEREFORD BARTON   \n",
       "1    2075   2743    COED ELY    COED ELY         COED ELY   \n",
       "2    6719   8798  PENYFFORDD  PENYFFORDD       PENYFFORDD   \n",
       "3    2622   3409       DERBY       DERBY            DERBY   \n",
       "4    4593   5966  INVERUGLAS  INVERUGLAS       INVERUGLAS   \n",
       "\n",
       "                                         Description Final Wikidata ID  \\\n",
       "0  [GW] op 2 January 1854  (T 29 December) ; clo ...         Q29379045   \n",
       "1  [GW] op 13 July 1925 (Cardiff Divisional Repor...          Q5140512   \n",
       "2  [GC] op 1 May 1866 (T 7 th ) ; still open. Ope...          Q3401808   \n",
       "3  [Birmingham & Derby Junction] temporary op 12 ...          Q3398679   \n",
       "4  [LNE] (non-tt): workmen, Loch Sloy HEP; op 29 ...         Q48807380   \n",
       "\n",
       "  Disambiguator                      Companies FirstCompanyWkdt  ...  \\\n",
       "0            []                           [GW]          Q843251  ...   \n",
       "1            []                           [GW]          Q843251  ...   \n",
       "2            []                           [GC]          Q688684  ...   \n",
       "3            []  [Birmingham & Derby Junction]         Q3700357  ...   \n",
       "4            []                          [LNE]         Q1092839  ...   \n",
       "\n",
       "                                Altnames Referenced     FirstOpening  \\\n",
       "0                                     []         []   2 January 1854   \n",
       "1                                     []         []     13 July 1925   \n",
       "2        [LEESWOOD, HOPE, HOPE JUNCTION]         []       1 May 1866   \n",
       "3  [DERBY MIDLAND, DERBY STATION STREET]         []      11 May 1840   \n",
       "4                                     []         []  29 October 1945   \n",
       "\n",
       "        LastClosing Interrupted our_method_all candrank_most_confident  \\\n",
       "0    2 January 1893       False      Q29379045               Q29379045   \n",
       "1       9 June 1958       False       Q5140512                Q5140512   \n",
       "2  31 December 2001       False       Q3401808                Q3401808   \n",
       "3  31 December 2001        True       Q3398679                Q3398679   \n",
       "4              1940       False      Q48807380               Q48807380   \n",
       "\n",
       "   wikipedia_most_relevant semantically_most_similar    ranklib  \n",
       "0                   Q23129                 Q29379045  Q29379045  \n",
       "1                 Q5140496                  Q5140496   Q5140512  \n",
       "2                 Q2752670                 Q28970438   Q3401808  \n",
       "3                   Q43475                  Q3398679   Q3398679  \n",
       "4                Q16892730                   Q799488  Q48807380  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Skyline: Best possible result given candidates\n",
    "# -------------------------------\n",
    "results_test_df = resolution_methods.skyline(features_test_df, results_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries in train and test: 82 81\n",
      "Instances in train and test: 336 4555\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "Classification report on the test split of the dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4467\n",
      "           1       0.97      0.77      0.86        88\n",
      "\n",
      "    accuracy                           1.00      4555\n",
      "   macro avg       0.98      0.89      0.93      4555\n",
      "weighted avg       1.00      1.00      0.99      4555\n",
      "\n",
      "[[ 1.51967785e+00 -5.58781562e-02 -5.63567062e-04  8.28458809e-06\n",
      "   2.74448717e-02  0.00000000e+00  5.35876468e-01  0.00000000e+00\n",
      "  -1.81169897e-03]]\n",
      "Queries in train and test: 24 23\n",
      "Instances in train and test: 216 115\n",
      "{'C': 1000, 'kernel': 'linear'}\n",
      "Classification report on the test split of the dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93       109\n",
      "           1       0.17      0.33      0.22         6\n",
      "\n",
      "    accuracy                           0.88       115\n",
      "   macro avg       0.56      0.62      0.58       115\n",
      "weighted avg       0.92      0.88      0.90       115\n",
      "\n",
      "[[ 0.          0.22313929  0.         -3.23703532  0.          0.59404004\n",
      "   0.          0.57320208 10.07739037]]\n",
      "0.5 0.6682027649769585\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Our method comb: Combine stations and places classifiers\n",
    "# -------------------------------\n",
    "\n",
    "use_cols_all = [\"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\"] \n",
    "\n",
    "# Train railway stations classifier (exact setting)\n",
    "# --------------------------------------------\n",
    "dev_df = features_dev # development set feature vectors\n",
    "df_exact = dev_df[dev_df[\"Exact\"] == 1]\n",
    "use_cols_stations = use_cols_all\n",
    "# Train the classifier:\n",
    "clf_stations = resolution_methods.train_classifier(df_exact, use_cols_all)\n",
    "\n",
    "# Train places classifier (not exact setting)\n",
    "# --------------------------------------------\n",
    "dev_df = features_dev # development set feature vectors\n",
    "df_inexact = dev_df[dev_df[\"Exact\"] == 0]\n",
    "use_cols_places = use_cols_all\n",
    "# Train the classifier:\n",
    "clf_places = resolution_methods.train_classifier(df_inexact, use_cols_all)\n",
    "\n",
    "# Find optimal threshold for stations/placess\n",
    "# --------------------------------------------\n",
    "optimal_threshold = 0.0\n",
    "keep_acc = 0.0\n",
    "for th in np.arange(0, 1, 0.05):\n",
    "    th = round(th, 2)\n",
    "    results_dev_df = pd.read_pickle(\"../processed/quicks/quicks_dev.pkl\")\n",
    "    results_dev_df = resolution_methods.our_method_comb(features_dev, clf_stations, use_cols_stations, clf_places, use_cols_places, gazetteer_df, th, results_dev_df)\n",
    "    acc = eval_methods.topres_exactmetrics(results_dev_df, \"our_method_comb\", False)\n",
    "    if acc >= keep_acc:\n",
    "        optimal_threshold = th\n",
    "        keep_acc = acc\n",
    "        \n",
    "print(optimal_threshold, keep_acc)\n",
    "\n",
    "# Apply our classification methods (column \"our_method\")\n",
    "# -------------------------------\n",
    "features_test_df = features_test # test set feature vectors\n",
    "results_test_df = resolution_methods.our_method_comb(features_test_df, clf_stations, use_cols_stations, clf_places, use_cols_places, gazetteer_df, optimal_threshold, results_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate entity resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skyline deezy_match (strict: True) (numCands: 1)\n",
      "candrank_most_confident deezy_match (strict: True) (numCands: 1)\n",
      "wikipedia_most_relevant deezy_match (strict: True) (numCands: 1)\n",
      "semantically_most_similar deezy_match (strict: True) (numCands: 1)\n",
      "ranklib deezy_match (strict: True) (numCands: 1)\n",
      "our_method_all deezy_match (strict: True) (numCands: 1)\n",
      "our_method_comb deezy_match (strict: True) (numCands: 1)\n",
      "\n",
      "\\begin{tabular}{llrlll}\n",
      "\\toprule\n",
      "  Eval &             Approach &  Prec & Acc@1km & Acc@5km & Acc@10km \\\\\n",
      "\\midrule\n",
      "strict &              skyline &  0.70 &       - &       - &        - \\\\\n",
      "strict &    string confidence &  0.63 &    0.67 &    0.72 &     0.72 \\\\\n",
      "strict &  wikipedia relevance &  0.07 &    0.41 &    0.65 &     0.66 \\\\\n",
      "strict &   semantic coherence &  0.32 &    0.48 &    0.63 &     0.63 \\\\\n",
      "strict & ranklib all features &  0.65 &    0.68 &    0.74 &     0.74 \\\\\n",
      "strict &           SVM simple &  0.67 &     0.7 &    0.73 &     0.73 \\\\\n",
      "strict &         SVM combined &  0.68 &    0.71 &    0.74 &     0.75 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_results = []\n",
    "eval_strict = True\n",
    "dApproachNames = {\"candrank_most_confident\":\"string confidence\", \"wikipedia_most_relevant\":\"wikipedia relevance\", \"semantically_most_similar\":\"semantic coherence\", \"our_method_all\":\"SVM simple\", \"our_method_comb\":\"SVM combined\", \"skyline\": \"skyline\",\"ranklib\":\"ranklib all features\"}\n",
    "for topres_approach in [\"skyline\", \"candrank_most_confident\", \"wikipedia_most_relevant\", \"semantically_most_similar\",\"ranklib\", \"our_method_all\", \"our_method_comb\"]:\n",
    "    print(topres_approach, candrank_method, \"(strict: \" + str(eval_strict) + \")\", \"(numCands: \" + str(num_candidates) + \")\")\n",
    "    exact_acc = eval_methods.topres_exactmetrics(results_test_df, topres_approach, eval_strict)\n",
    "    acc_at = (\"-\", \"-\", \"-\")\n",
    "    if topres_approach != \"skyline\":\n",
    "        acc_at = eval_methods.topres_distancemetrics(gazetteer_df, results_test_df, topres_approach, eval_strict)\n",
    "\n",
    "    eval_mode = \"strict\"\n",
    "    if eval_strict == False:\n",
    "        eval_mode = \"appr\"\n",
    "        \n",
    "    eval_results.append([eval_mode, dApproachNames[topres_approach], exact_acc, acc_at[0], acc_at[1], acc_at[2]])\n",
    "\n",
    "tr_eval_df = pd.DataFrame(eval_results, columns = [\"Eval\", \"Approach\", \"Prec\", \"Acc@1km\", \"Acc@5km\", \"Acc@10km\"])\n",
    "tr_eval_df.round(3)\n",
    "print()\n",
    "print(tr_eval_df.round(2).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Inspect best features in ranklib\n",
    "code_folder = str(Path(\"../../\").resolve()) + \"/\"\n",
    "features_folder = str(Path(\"supervised_ranking/features/\").resolve()) + \"/\"\n",
    "Path(features_folder).mkdir(parents=True, exist_ok=True)\n",
    "Path(\"supervised_ranking/feature_combs/\").mkdir(parents=True, exist_ok=True)\n",
    "cross_val = True\n",
    "for filt in [\"exact\", \"notexact\"]:\n",
    "    if not Path(\"supervised_ranking/feature_combs/\" + filt + str(num_candidates) + \".txt\").is_file():\n",
    "        feature_combination = resolution_methods.find_feature_comb(features_folder, filt, cross_val, code_folder, features_dev, features_test_df, results_test_df, num_candidates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37deezy)",
   "language": "python",
   "name": "py37deezy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "f8f99ba867f8acd4dfef7d85ca8ca3fc6c0cf34252ca432008145451d1a4a38c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
