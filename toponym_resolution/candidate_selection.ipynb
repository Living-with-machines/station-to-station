{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from tools import eval_methods, selection_methods, resolution_methods\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df = pd.read_pickle(\"../processed/quicks/quicks_dev.pkl\")\n",
    "alts_df = pd.read_pickle(\"../processed/quicks/quicks_altname_dev.pkl\")\n",
    "wkdt_alts_df = pd.read_pickle(\"../processed/wikidata/altname_british_isles_stations_gazetteer.pkl\")\n",
    "gazetteer_df = pd.read_csv(\"../processed/wikidata/british_isles_gazetteer.csv\", header=0, index_col=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# Skyline: best possible result considering NIL entities\n",
    "approach = \"cr_skyline\"\n",
    "df[approach] = df.apply(lambda row: selection_methods.skyline(row[\"Final Wikidata ID\"], wkdt_alts_df), axis=1)\n",
    "\n",
    "# ---------------\n",
    "# Perfect Match\n",
    "approach = \"cr_perfect_match\"\n",
    "df[approach] = df.apply(lambda row: selection_methods.perfect_match(row[\"SubStFormatted\"], wkdt_alts_df), axis=1)\n",
    "df.apply(lambda row: selection_methods.perfect_match(row[\"SubStFormatted\"], wkdt_alts_df), axis=1)\n",
    "\n",
    "# ---------------\n",
    "# Partial Match\n",
    "approach = \"cr_partial_match\"\n",
    "df[approach] = df.apply(lambda row: selection_methods.partial_match(row[\"SubStFormatted\"], wkdt_alts_df), axis=1)\n",
    "\n",
    "# ---------------\n",
    "# DeezyMatch\n",
    "approach = \"cr_deezy_match\"\n",
    "candidates = \"british_isles_stations\"\n",
    "dm_model = \"wikidata_british_isles\"\n",
    "inputfile = \"input_dfm\"\n",
    "queries = \"quicks_stations\"\n",
    "candrank_metric = \"faiss\" # 'faiss', 'cosine', 'conf'\n",
    "candrank_thr = 5\n",
    "num_candidates = 10\n",
    "quicks_query_column = \"SubStFormatted\"\n",
    "\n",
    "df[approach] = selection_methods.find_deezymatch_candidates(wkdt_alts_df, df, quicks_query_column, dm_model, inputfile, candidates, queries, candrank_metric, candrank_thr, num_candidates)\n",
    "\n",
    "# ----------------\n",
    "# DeezyMatch: altnames\n",
    "approach = \"cr_deezy_match_alts\"\n",
    "candidates = \"british_isles_stations\"\n",
    "dm_model = \"wikidata_british_isles\"\n",
    "inputfile = \"input_dfm\"\n",
    "queries = \"quicks_stations\"\n",
    "candrank_metric = \"faiss\" # 'faiss', 'cosine', 'conf'\n",
    "candrank_thr = 5\n",
    "num_candidates = 3\n",
    "quicks_query_column = \"Altname\"\n",
    "\n",
    "alts_df[approach] = selection_methods.find_deezymatch_candidates(wkdt_alts_df, alts_df, quicks_query_column, dm_model, inputfile, candidates, queries, candrank_metric, candrank_thr, num_candidates)\n",
    "# Add deezymatch altnames to dataframe:\n",
    "dAlts = dict()\n",
    "altn_candidates = []\n",
    "for i, row in alts_df.iterrows():\n",
    "    if row[\"SubId\"] in dAlts:\n",
    "        dAlts[row[\"SubId\"]].update(row[\"cr_deezy_match_alts\"])\n",
    "    else:\n",
    "        dAlts[row[\"SubId\"]] = row[\"cr_deezy_match_alts\"]\n",
    "for i, row in df.iterrows():\n",
    "    if row[\"SubId\"] in dAlts:\n",
    "        altn_candidates.append(dict(OrderedDict(dAlts[row[\"SubId\"]])))\n",
    "    else:\n",
    "        altn_candidates.append(dict())\n",
    "df[approach] = altn_candidates\n",
    "\n",
    "# ---------------\n",
    "# Store candidate selection\n",
    "df.to_pickle(\"candranking_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cr_skyline\n",
      "p1: 0.8\n",
      "p5: 0.8\n",
      "p10: 0.8\n",
      "map5: 0.8\n",
      "map10: 0.8\n",
      "\n",
      "cr_perfect_match\n",
      "p1: 0.5674418604651162\n",
      "p5: 0.6046511627906976\n",
      "p10: 0.6046511627906976\n",
      "map5: 0.586046511627907\n",
      "map10: 0.586046511627907\n",
      "\n",
      "cr_partial_match\n",
      "p1: 0.4697674418604651\n",
      "p5: 0.6\n",
      "p10: 0.627906976744186\n",
      "map5: 0.5267441860465116\n",
      "map10: 0.5312846068660022\n",
      "\n",
      "cr_deezy_match\n",
      "p1: 0.6\n",
      "p5: 0.641860465116279\n",
      "p10: 0.641860465116279\n",
      "map5: 0.6197674418604651\n",
      "map10: 0.6197674418604651\n",
      "\n",
      "cr_deezy_match_alts\n",
      "p1: 0.06046511627906977\n",
      "p5: 0.11627906976744186\n",
      "p10: 0.11627906976744186\n",
      "map5: 0.08310077519379845\n",
      "map10: 0.08310077519379845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"candranking_df.pkl\")\n",
    "candrank_approaches = [x for x in df if x.startswith(\"cr_\")]\n",
    "\n",
    "for approach in candrank_approaches:\n",
    "    print(approach)\n",
    "    print(\"p1:\", df.apply(lambda row: eval_methods.pAt(row, approach, 1, False), axis=1).mean())\n",
    "    print(\"p5:\", df.apply(lambda row: eval_methods.pAt(row, approach, 5, False), axis=1).mean())\n",
    "    print(\"p10:\", df.apply(lambda row: eval_methods.pAt(row, approach, 10, False), axis=1).mean())\n",
    "    print(\"map5:\", df.apply(lambda row: eval_methods.avgP(row, approach, 5, False), axis=1).mean())\n",
    "    print(\"map10:\", df.apply(lambda row: eval_methods.avgP(row, approach, 10, False), axis=1).mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topres_approach = \"first_match\"\n",
    "candrank_approach = \"cr_deezy_match\"\n",
    "column_name = candrank_approach + \"_\" + topres_approach\n",
    "df_resolved = df.copy()\n",
    "\n",
    "# Resolution methods\n",
    "df_resolved[column_name] = df_resolved.apply(lambda row: resolution_methods.first_match(row[candrank_approach], wkdt_alts_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.3953488372093023\n",
      "Accuracy Score: 0.6046511627906976\n",
      "Jaccard Score: 0.5543290043290043\n",
      "Accuracy at 1: 0.6465116279069767\n",
      "Accuracy at 5: 0.7209302325581395\n",
      "Accuracy at 10: 0.7209302325581395\n"
     ]
    }
   ],
   "source": [
    "# Evaluation methods\n",
    "eval_methods.topres_exactmetrics(df_resolved, column_name)\n",
    "eval_methods.topres_distancemetrics(gazetteer_df, df_resolved, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37deezy)",
   "language": "python",
   "name": "py37deezy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
