{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from tools import eval_methods, selection_methods\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "setting = \"dev\" # dev or test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform candidate selection and ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not Path(\"candranking_\" + setting + \".pkl\").is_file():\n",
    "\n",
    "    df = pd.read_pickle(\"../processed/quicks/quicks_\" + setting + \".pkl\")\n",
    "    alts_df = pd.read_pickle(\"../processed/quicks/quicks_altname_\" + setting + \".pkl\")\n",
    "    wkdt_df_places = pd.read_pickle(\"../processed/wikidata/altname_british_isles_gazetteer.pkl\")\n",
    "    wkdt_df_stations = pd.read_pickle(\"../processed/wikidata/altname_british_isles_stations_gazetteer.pkl\")\n",
    "\n",
    "    # ---------------\n",
    "    # Perfect Match\n",
    "    df[\"cr_perfect_match_stations\"] = df.apply(lambda row: selection_methods.perfect_match(row[\"SubStFormatted\"], wkdt_df_stations), axis=1)\n",
    "    df[\"cr_perfect_match_places\"] = df.apply(lambda row: selection_methods.perfect_match(row[\"MainStation\"], wkdt_df_places), axis=1)\n",
    "    alts_df[\"cr_perfect_match_alts\"] = alts_df.apply(lambda row: selection_methods.perfect_match(row[\"Altname\"], wkdt_df_stations), axis=1)\n",
    "    print(\"Perfect match done!\")\n",
    "\n",
    "    # ---------------\n",
    "    # Partial Match\n",
    "    df[\"cr_partial_match_stations\"] = df.apply(lambda row: selection_methods.partial_match(row[\"SubStFormatted\"], wkdt_df_stations), axis=1)\n",
    "    df[\"cr_partial_match_places\"] = df.apply(lambda row: selection_methods.partial_match(row[\"MainStation\"], wkdt_df_places), axis=1)\n",
    "    alts_df[\"cr_partial_match_alts\"] = alts_df.apply(lambda row: selection_methods.partial_match(row[\"Altname\"], wkdt_df_stations), axis=1)\n",
    "    print(\"Partial match done!\")\n",
    "\n",
    "    # ---------------\n",
    "    # DeezyMatch\n",
    "    candidates = \"british_isles_stations\"\n",
    "    dm_model = \"wikidata_british_isles\"\n",
    "    inputfile = \"input_dfm\"\n",
    "    queries = \"quicks_stations\"\n",
    "    candrank_metric = \"faiss\" # 'faiss', 'cosine', 'conf'\n",
    "    candrank_thr = 5\n",
    "    num_candidates = 3\n",
    "    quicks_query_column = \"SubStFormatted\"\n",
    "    df[\"cr_deezy_match_stations\"] = selection_methods.find_deezymatch_candidates(wkdt_df_stations, df, quicks_query_column, dm_model, inputfile, candidates, queries, candrank_metric, candrank_thr, num_candidates)\n",
    "\n",
    "    candidates = \"british_isles\"\n",
    "    dm_model = \"wikidata_british_isles\"\n",
    "    inputfile = \"input_dfm\"\n",
    "    queries = \"quicks_places\"\n",
    "    candrank_metric = \"faiss\" # 'faiss', 'cosine', 'conf'\n",
    "    candrank_thr = 5\n",
    "    num_candidates = 3\n",
    "    quicks_query_column = \"MainStation\"\n",
    "    df[\"cr_deezy_match_places\"] = selection_methods.find_deezymatch_candidates(wkdt_df_places, df, quicks_query_column, dm_model, inputfile, candidates, queries, candrank_metric, candrank_thr, num_candidates)\n",
    "\n",
    "    candidates = \"british_isles_stations\"\n",
    "    dm_model = \"wikidata_british_isles\"\n",
    "    inputfile = \"input_dfm\"\n",
    "    queries = \"quicks_altns\"\n",
    "    candrank_metric = \"faiss\" # 'faiss', 'cosine', 'conf'\n",
    "    candrank_thr = 5\n",
    "    num_candidates = 3\n",
    "    quicks_query_column = \"Altname\"\n",
    "    alts_df[\"cr_deezy_match_alts\"] = selection_methods.find_deezymatch_candidates(wkdt_df_stations, alts_df, quicks_query_column, dm_model, inputfile, candidates, queries, candrank_metric, candrank_thr, num_candidates)\n",
    "    print(\"Deezy match done!\")\n",
    "\n",
    "    # Add altnames to dataframe:\n",
    "    # Add deezymatch altnames to dataframe:\n",
    "    for appr in [\"perfect_match\", \"partial_match\", \"deezy_match\"]:\n",
    "        dAlts = dict()\n",
    "        altn_candidates = []\n",
    "        for i, row in alts_df.iterrows():\n",
    "            if row[\"SubId\"] in dAlts:\n",
    "                dAlts[row[\"SubId\"]].update(row[\"cr_\" + appr + \"_alts\"])\n",
    "            else:\n",
    "                dAlts[row[\"SubId\"]] = row[\"cr_\" + appr + \"_alts\"]\n",
    "        for i, row in df.iterrows():\n",
    "            if row[\"SubId\"] in dAlts:\n",
    "                altn_candidates.append(dict(OrderedDict(dAlts[row[\"SubId\"]])))\n",
    "            else:\n",
    "                altn_candidates.append(dict())\n",
    "        df[\"cr_\" + appr + \"_alts\"] = altn_candidates\n",
    "\n",
    "    # ---------------\n",
    "    # Store candidate selection\n",
    "    df.to_pickle(\"candranking_\" + setting + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate candidate selection and raking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      "      Sources &             Approach &    p1 &    p5 &   p10 &  map5 &  map10 &  isRetrieved \\\\\n",
      "\\midrule\n",
      "perfect\\_match &             stations & 0.670 & 0.710 & 0.710 & 0.689 &  0.689 &        0.710 \\\\\n",
      "partial\\_match &             stations & 0.674 & 0.715 & 0.719 & 0.692 &  0.692 &        0.719 \\\\\n",
      "  deezy\\_match &             stations & 0.688 & 0.733 & 0.733 & 0.709 &  0.709 &        0.733 \\\\\n",
      "perfect\\_match &        stations+alts & 0.683 & 0.724 & 0.724 & 0.703 &  0.703 &        0.724 \\\\\n",
      "partial\\_match &        stations+alts & 0.656 & 0.724 & 0.733 & 0.686 &  0.688 &        0.733 \\\\\n",
      "  deezy\\_match &        stations+alts & 0.683 & 0.747 & 0.747 & 0.712 &  0.712 &        0.747 \\\\\n",
      "perfect\\_match &      stations+places & 0.710 & 0.769 & 0.774 & 0.737 &  0.738 &        0.774 \\\\\n",
      "partial\\_match &      stations+places & 0.181 & 0.389 & 0.543 & 0.250 &  0.271 &        0.665 \\\\\n",
      "  deezy\\_match &      stations+places & 0.715 & 0.787 & 0.796 & 0.746 &  0.747 &        0.796 \\\\\n",
      "perfect\\_match & stations+places+alts & 0.724 & 0.783 & 0.787 & 0.751 &  0.751 &        0.787 \\\\\n",
      "partial\\_match & stations+places+alts & 0.199 & 0.398 & 0.561 & 0.268 &  0.290 &        0.688 \\\\\n",
      "  deezy\\_match & stations+places+alts & 0.670 & 0.769 & 0.801 & 0.708 &  0.713 &        0.810 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_pickle(\"candranking_test.pkl\")\n",
    "\n",
    "combinations = [[\"stations\"], [\"stations\", \"alts\"], [\"stations\", \"places\"], [\"stations\", \"places\", \"alts\"]]\n",
    "candrank_approaches = [x.replace(\"cr_\", \"\").replace(\"_stations\", \"\") for x in test_df if x.startswith(\"cr_\") and x.endswith(\"stations\")]\n",
    "\n",
    "eval_results = []\n",
    "for combination in combinations:\n",
    "    for approach in candrank_approaches:\n",
    "        \n",
    "        # Get relevant columns from dataframe:\n",
    "        relv_columns = []\n",
    "        for c in combination:\n",
    "            relv_columns.append(\"cr_\" + approach + \"_\" + c)\n",
    "            \n",
    "        reverse_values = False if approach == \"deezy_match\" else True\n",
    "        \n",
    "        # Report performance:\n",
    "        p1 = test_df.apply(lambda row: eval_methods.pAt(row, approach, relv_columns, 1, reverse_values), axis=1).mean()\n",
    "        p5 = test_df.apply(lambda row: eval_methods.pAt(row, approach, relv_columns, 5, reverse_values), axis=1).mean()\n",
    "        p10 = test_df.apply(lambda row: eval_methods.pAt(row, approach, relv_columns, 10, reverse_values), axis=1).mean()\n",
    "        map5 = test_df.apply(lambda row: eval_methods.avgP(row, approach, relv_columns, 5, reverse_values), axis=1).mean()\n",
    "        map10 = test_df.apply(lambda row: eval_methods.avgP(row, approach, relv_columns, 10, reverse_values), axis=1).mean()\n",
    "        isRetrieved = test_df.apply(lambda row: eval_methods.isRetrieved(row, approach, relv_columns, 20, reverse_values), axis=1).mean()\n",
    "        eval_results.append([approach, \"+\".join(combination), p1, p5, p10, map5, map10, isRetrieved])\n",
    "        \n",
    "cr_eval_df = pd.DataFrame(eval_results, columns = [\"Sources\", \"Approach\", \"p1\", \"p5\", \"p10\", \"map5\", \"map10\", \"isRetrieved\"])\n",
    "cr_eval_df.round(3)\n",
    "print(cr_eval_df.round(3).to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37deezy)",
   "language": "python",
   "name": "py37deezy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
