{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils\n",
    "import pandas as pd\n",
    "import collections\n",
    "import ast\n",
    "from wikimapper import WikiMapper\n",
    "from pathlib import Path\n",
    "import urllib.parse\n",
    "import json\n",
    "import html\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "candidates = \"stnwikidata_candidates\"\n",
    "min_wkdtgazetteer = \"stnwikidata_gazetteer\"\n",
    "max_wkdtgazetteer = \"british_isles_stations\"\n",
    "queries_mainst = \"quicks_mainst_queries\"\n",
    "queries_subst = \"quicks_subst_queries\"\n",
    "queries_altns = \"quicks_altnames\"\n",
    "queries_refs = \"quicks_referenced\"\n",
    "dm_model = \"wikigaz_en_002\"\n",
    "candrank_metric = \"faiss\" # 'faiss', 'cosine', 'conf'\n",
    "mapper = WikiMapper(\"/resources/wikidata2wikipedia/index_enwiki-20190420.db\") # WikiMapper object (see https://pypi.org/project/wikimapper/)\n",
    "wikipedia_path = \"/resources/wikipedia/extractedResources/Aspects/\"\n",
    "\n",
    "# Load candidate ranking results:\n",
    "quicks_mainst_cands = pd.read_pickle(\"../../toponym_matching/ranker_results/\" + queries_mainst + \"_\" + candidates + \"_\" + dm_model + \"_\" + candrank_metric + \".pkl\")\n",
    "quicks_subst_cands = pd.read_pickle(\"../../toponym_matching/ranker_results/\" + queries_subst + \"_\" + candidates + \"_\" + dm_model + \"_\" + candrank_metric + \".pkl\")\n",
    "quicks_altns_cands = pd.read_pickle(\"../../toponym_matching/ranker_results/\" + queries_altns + \"_\" + candidates + \"_\" + dm_model + \"_\" + candrank_metric + \".pkl\")\n",
    "quicks_refs_cands = pd.read_pickle(\"../../toponym_matching/ranker_results/\" + queries_refs + \"_\" + candidates + \"_\" + dm_model + \"_\" + candrank_metric + \".pkl\")\n",
    "\n",
    "# Load minimal wikidata gazetteer (fields: wkid, altname, source, lat, lon) from which candidates were created:\n",
    "wikidatagaz_df = pd.read_pickle(\"../../toponym_matching/gazetteers/\" + min_wkdtgazetteer + \".pkl\")\n",
    "\n",
    "# Load maximal wikidata gazetteer (fields: wikidata_id, english_label, instance_of, description_set...):\n",
    "wikidata_gazetteer = pd.read_csv(\"../../wikidata/\" + max_wkdtgazetteer + \".csv\", index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# Function that finds the Wikidata IDs of DeezyMatch's returned matches.\n",
    "# * Input:\n",
    "#     * row: a ranker_results df row (fields: id, query, pred_score,\n",
    "#            faiss_distance, cosine_sim, ...)\n",
    "#     * gazetteer: gazetteer where candidates have been obtained from\n",
    "#                  (fields: wkid, altname, source, lat, lon)\n",
    "#     * ranking: candidate ranking metric (must be one column of the\n",
    "#                'row' argument.)\n",
    "# * Output: a dictionary with DeezyMatch candidates aligned with their\n",
    "#           Wikidata IDs, per row.\n",
    "re_station = r\"( \\b(([Rr]ailw[ae]y [Ss]tation)|([Bb]us [Ss]tation)|([Uu]nderground [Ss]tation)|([Tt]ram [Ss]top)|([Hh]alt)|([Ss]top)|([Ss]tation))((\\, .*)|( \\(.*))?)$\"\n",
    "def match_cands_wikidata(row,gazetteer,ranking):\n",
    "    wikidata_cands = {}\n",
    "    cands = list(row[ranking].items())[:3] # Closest three matches.\n",
    "    for cand,score in cands:\n",
    "        wikidataIds = gazetteer[gazetteer[\"altname\"].str.contains(r\"^\" + cand + re_station, regex = True)][\"wkid\"]\n",
    "        for _id in wikidataIds:\n",
    "            if _id not in wikidata_cands:\n",
    "                wikidata_cands[_id] = score\n",
    "    return wikidata_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(\"quicks_mainst_cands.pkl\").exists():\n",
    "    quicks_mainst_cands[\"wikidata_cands\"] = quicks_mainst_cands.progress_apply(lambda row : match_cands_wikidata(row,wikidatagaz_df,\"faiss_distance\"), axis=1)\n",
    "    quicks_subst_cands[\"wikidata_cands\"] = quicks_subst_cands.progress_apply(lambda row : match_cands_wikidata(row,wikidatagaz_df,\"faiss_distance\"), axis=1)\n",
    "    quicks_altns_cands[\"wikidata_cands\"] = quicks_altns_cands.progress_apply(lambda row : match_cands_wikidata(row,wikidatagaz_df,\"faiss_distance\"), axis=1)\n",
    "    quicks_refs_cands[\"wikidata_cands\"] = quicks_refs_cands.progress_apply(lambda row : match_cands_wikidata(row,wikidatagaz_df,\"faiss_distance\"), axis=1)\n",
    "    quicks_mainst_cands.to_pickle(\"quicks_mainst_cands.pkl\")\n",
    "    quicks_subst_cands.to_pickle(\"quicks_subst_cands.pkl\")\n",
    "    quicks_altns_cands.to_pickle(\"quicks_altns_cands.pkl\")\n",
    "    quicks_refs_cands.to_pickle(\"quicks_refs_cands.pkl\")\n",
    "\n",
    "quicks_mainst_cands = pd.read_pickle(\"quicks_mainst_cands.pkl\")\n",
    "quicks_subst_cands = pd.read_pickle(\"quicks_subst_cands.pkl\")\n",
    "quicks_altns_cands = pd.read_pickle(\"quicks_altns_cands.pkl\")\n",
    "quicks_refs_cands = pd.read_pickle(\"quicks_refs_cands.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv-structured Quicks dataset:\n",
    "quicks_dataset = pd.read_pickle(\"../../quick/quicks_processed.pkl\")\n",
    "quicks_altnames = pd.read_pickle(\"../../quick/quicks_altnames_df.pkl\")\n",
    "quicks_referenced = pd.read_pickle(\"../../quick/quicks_referenced_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main2df = []\n",
    "sub2df = []\n",
    "alt2df = []\n",
    "ref2df = []\n",
    "for i, row in quicks_dataset.iterrows():\n",
    "    mainId = row[\"MainId\"]\n",
    "    subId = row[\"SubId\"]\n",
    "    mainName = row[\"MainStation\"]\n",
    "    subName = row[\"SubStFormatted\"]\n",
    "    \n",
    "    # Main station cands:\n",
    "    main_cands = dict()\n",
    "    mains = tuple(quicks_mainst_cands[quicks_mainst_cands[\"query\"] == mainName][\"wikidata_cands\"].values)\n",
    "    for mc in mains:\n",
    "        for k in mc:\n",
    "            if k in main_cands:\n",
    "                if main_cands[k] > mc[k]:\n",
    "                    main_cands[k] = mc[k]\n",
    "            else:\n",
    "                main_cands[k] = mc[k]\n",
    "        \n",
    "    # Substation cands:\n",
    "    subst_cands = dict()\n",
    "    subs = tuple(quicks_subst_cands[quicks_subst_cands[\"query\"] == subName][\"wikidata_cands\"].values)\n",
    "    for mc in subs:\n",
    "        for k in mc:\n",
    "            if k in subst_cands:\n",
    "                if subst_cands[k] > subs[k]:\n",
    "                    subst_cands[k] = mc[k]\n",
    "            else:\n",
    "                subst_cands[k] = mc[k]\n",
    "        \n",
    "    # Altnames for stations cands:\n",
    "    alts = quicks_altnames[(quicks_altnames[\"MainId\"] == mainId) & (quicks_altnames[\"SubId\"] == subId)][\"Altname\"].tolist()\n",
    "    alt_cands = dict()\n",
    "    for a in alts:\n",
    "        for item in quicks_altns_cands[quicks_altns_cands[\"query\"] == a][\"wikidata_cands\"].values:\n",
    "            for k, v in item.items():\n",
    "                if k in alt_cands:\n",
    "                    if alt_cands[k] > v:\n",
    "                        alt_cands[k] = v\n",
    "                else:\n",
    "                    alt_cands[k] = v\n",
    "                    \n",
    "    # Referenced station names cands:\n",
    "    refs = quicks_referenced[(quicks_referenced[\"MainId\"] == mainId) & (quicks_referenced[\"SubId\"] == subId)][\"Referenced\"].tolist()\n",
    "    ref_cands = dict()\n",
    "    for a in refs:\n",
    "        for item in quicks_refs_cands[quicks_refs_cands[\"query\"] == a][\"wikidata_cands\"].values:\n",
    "            for k, v in item.items():\n",
    "                if k in ref_cands:\n",
    "                    if ref_cands[k] > v:\n",
    "                        ref_cands[k] = v\n",
    "                else:\n",
    "                    ref_cands[k] = v\n",
    "                    \n",
    "    main2df.append(main_cands)\n",
    "    sub2df.append(subst_cands)\n",
    "    alt2df.append(alt_cands)\n",
    "    ref2df.append(ref_cands)\n",
    "    \n",
    "quicks_dataset[\"MainstWkdt\"] = main2df\n",
    "quicks_dataset[\"SubstWkdt\"] = sub2df\n",
    "quicks_dataset[\"AltnmWkdt\"] = alt2df\n",
    "quicks_dataset[\"RefdWkdt\"] = ref2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37deezy)",
   "language": "python",
   "name": "py37deezy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
