{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time,os,json\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "def fill_dicts(res):\n",
    "    global mentions_freq, entity_freq, ngrams_freq, mention_overall_dict\n",
    "    \n",
    "    url,box_mentions, content_ngrams, box_entities, mentions_dict = res[0],res[1],res[2],res[3],res[4]\n",
    "    mentions_freq+= box_mentions\n",
    "    ngrams_freq+= content_ngrams\n",
    "    entity_freq+= box_entities\n",
    "    \n",
    "    for k,v in box_entities.items():\n",
    "        if k in entity_overall_dict:\n",
    "            entity_overall_dict[k].append(url)\n",
    "        else:\n",
    "            entity_overall_dict[k] = [url]\n",
    "    \n",
    "    for k,v in mentions_dict.items():\n",
    "        if k in mention_overall_dict:\n",
    "            mention_overall_dict[k]+=v\n",
    "        else:\n",
    "            mention_overall_dict[k] = Counter()\n",
    "            mention_overall_dict[k]+= v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 1.json\n",
      "Since beginning: 00:09:27, Last step: 00:09:27\n",
      "done: 2.json\n",
      "Since beginning: 00:18:56, Last step: 00:09:29\n",
      "done: 3.json\n",
      "Since beginning: 00:28:56, Last step: 00:09:59\n",
      "done: 4.json\n",
      "Since beginning: 00:42:13, Last step: 00:13:17\n",
      "done: 5.json\n",
      "Since beginning: 00:54:16, Last step: 00:12:02\n",
      "done: 6.json\n",
      "Since beginning: 01:07:33, Last step: 00:13:16\n",
      "done: 7.json\n",
      "Since beginning: 01:23:27, Last step: 00:15:54\n",
      "done: 8.json\n",
      "Since beginning: 01:42:05, Last step: 00:18:38\n",
      "done: 9.json\n",
      "Since beginning: 01:59:17, Last step: 00:17:12\n",
      "done: 10.json\n",
      "Since beginning: 02:14:26, Last step: 00:15:08\n",
      "done: 11.json\n",
      "Since beginning: 02:33:09, Last step: 00:18:42\n",
      "done: 12.json\n",
      "Since beginning: 02:51:14, Last step: 00:18:05\n",
      "done: 13.json\n",
      "Since beginning: 03:09:53, Last step: 00:18:38\n",
      "done: 14.json\n",
      "Since beginning: 03:31:57, Last step: 00:22:04\n",
      "done: 15.json\n",
      "Since beginning: 03:54:10, Last step: 00:22:12\n",
      "done: 16.json\n",
      "Since beginning: 04:15:25, Last step: 00:21:15\n",
      "done: 17.json\n",
      "Since beginning: 04:39:54, Last step: 00:24:28\n",
      "done: 18.json\n",
      "Since beginning: 05:02:47, Last step: 00:22:53\n",
      "done: 19.json\n",
      "Since beginning: 05:27:50, Last step: 00:25:02\n",
      "done: 20.json\n",
      "Since beginning: 05:53:46, Last step: 00:25:55\n"
     ]
    }
   ],
   "source": [
    "overall_mentions_freq = Counter()\n",
    "overall_entity_freq = Counter()\n",
    "overall_ngrams_freq =  Counter()\n",
    "\n",
    "mention_overall_dict = {}\n",
    "entity_overall_dict = {}\n",
    "\n",
    "\n",
    "with open(\"/resources/wikipedia/extractedResources//overall_mentions_freq.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(overall_mentions_freq, fp)\n",
    "\n",
    "with open(\"/resources/wikipedia/extractedResources//overall_entity_freq.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(overall_entity_freq, fp)\n",
    "    \n",
    "with open(\"/resources/wikipedia/extractedResources//overall_ngrams_freq.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(overall_ngrams_freq, fp)\n",
    "    \n",
    "json_folder = \"/resources/wikipedia/extractedResources/Store-Counts/\"\n",
    "\n",
    "start_time = time.time()\n",
    "previous = start_time\n",
    "jsons = [x for x in os.listdir(json_folder) if \".json\" in x]\n",
    "\n",
    "for filename in jsons:\n",
    "    \n",
    "    mentions_freq = Counter()\n",
    "    entity_freq = Counter()\n",
    "    ngrams_freq =  Counter()\n",
    "    \n",
    "    with open(json_folder+filename) as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "        for res in data:\n",
    "            fill_dicts(res)\n",
    "         \n",
    "    with open(\"/resources/wikipedia/extractedResources//overall_mentions_freq.pickle\", \"rb\") as f:\n",
    "        overall_mentions_freq = pickle.load(f)\n",
    "        \n",
    "    overall_mentions_freq += mentions_freq\n",
    "    \n",
    "    with open(\"/resources/wikipedia/extractedResources//overall_mentions_freq.pickle\", \"wb\") as fp:\n",
    "        pickle.dump(overall_mentions_freq, fp)\n",
    "        \n",
    "        \n",
    "    with open(\"/resources/wikipedia/extractedResources//overall_entity_freq.pickle\", \"rb\") as f:\n",
    "        overall_entity_freq = pickle.load(f)\n",
    "        \n",
    "    overall_entity_freq += entity_freq\n",
    "    \n",
    "    with open(\"/resources/wikipedia/extractedResources//overall_entity_freq.pickle\", \"wb\") as fp:\n",
    "        pickle.dump(overall_entity_freq, fp)\n",
    "\n",
    "        \n",
    "    with open(\"/resources/wikipedia/extractedResources//overall_ngrams_freq.pickle\", \"rb\") as f:\n",
    "        overall_ngrams_freq = pickle.load(f)\n",
    "        \n",
    "    overall_ngrams_freq += ngrams_freq\n",
    "    \n",
    "    with open(\"/resources/wikipedia/extractedResources//overall_ngrams_freq.pickle\", \"wb\") as fp:\n",
    "        pickle.dump(overall_ngrams_freq, fp)\n",
    "    \n",
    "    with open(\"/resources/wikipedia/extractedResources//mention_overall_dict.pickle\", \"wb\") as fp:\n",
    "        pickle.dump(mention_overall_dict, fp)\n",
    "    \n",
    "    with open(\"/resources/wikipedia/extractedResources//entity_overall_dict.pickle\", \"wb\") as fp:\n",
    "        pickle.dump(entity_overall_dict, fp)\n",
    "    \n",
    "    print (\"done:\", filename)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    diff = time.time() - previous\n",
    "    since_beginning = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "    last_step = time.strftime(\"%H:%M:%S\", time.gmtime(diff))\n",
    "    \n",
    "    print(\"Since beginning: %s, Last step: %s\" % (since_beginning,last_step))\n",
    "    previous = time.time()\n",
    "    \n",
    "print (\"all done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
